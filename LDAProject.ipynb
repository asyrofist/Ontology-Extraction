{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import os\n",
    "import gensim\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaryDir = \"./Datasets/Summaries\"\n",
    "summaryFiles = os.listdir(summaryDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for sFile in summaryFiles:\n",
    "    f = open(os.path.join(summaryDir,sFile))\n",
    "    documents.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'Documents':documents})   # Creating data frame for documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(doc):\n",
    "    stopFree = \" \".join([word for word in doc.lower().split() if word not in stopWords])\n",
    "    puncFree = \"\".join([word for word in stopFree if word not in exclude])\n",
    "    normalized = \" \".join([lemma.lemmatize(word) for word in puncFree.split()])\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Clean Documents'] = data['Documents'].map(clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Now the Dataframe will contain the documents and their cleaned (normalized versions) with it ```\n",
    "\n",
    "``` Now creating Bag Of Words on the Dataset ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Bag of Words\n",
    "docsForDict = []\n",
    "for doc in data['Clean Documents']:\n",
    "    tokens = doc.split()\n",
    "    docsForDict.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Token Lists'] = docsForDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(data['Token Lists'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagOfWords = [dictionary.doc2bow(doc) for doc in data['Token Lists']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: 19 : also appears 2 times.\n",
      "Word: 20 : analysis appears 2 times.\n",
      "Word: 24 : analyzing appears 1 times.\n",
      "Word: 26 : argument appears 1 times.\n",
      "Word: 31 : assumed appears 1 times.\n",
      "Word: 37 : case appears 1 times.\n",
      "Word: 51 : consists appears 1 times.\n",
      "Word: 55 : could appears 1 times.\n",
      "Word: 67 : every appears 1 times.\n",
      "Word: 74 : first appears 1 times.\n",
      "Word: 82 : identifying appears 2 times.\n",
      "Word: 85 : instance appears 1 times.\n",
      "Word: 97 : must appears 1 times.\n",
      "Word: 102 : one appears 1 times.\n",
      "Word: 103 : order appears 1 times.\n",
      "Word: 110 : relation appears 1 times.\n",
      "Word: 115 : respectively appears 1 times.\n",
      "Word: 117 : result appears 1 times.\n",
      "Word: 120 : section appears 6 times.\n",
      "Word: 127 : set appears 6 times.\n",
      "Word: 131 : since appears 1 times.\n",
      "Word: 133 : source appears 1 times.\n",
      "Word: 135 : structure appears 18 times.\n",
      "Word: 140 : therefore appears 1 times.\n",
      "Word: 142 : three appears 1 times.\n",
      "Word: 143 : tree appears 33 times.\n",
      "Word: 144 : two appears 7 times.\n",
      "Word: 146 : use appears 2 times.\n",
      "Word: 147 : used appears 5 times.\n",
      "Word: 149 : using appears 1 times.\n",
      "Word: 152 : would appears 1 times.\n",
      "Word: 153 : a appears 1 times.\n",
      "Word: 164 : cannot appears 3 times.\n",
      "Word: 179 : determined appears 1 times.\n",
      "Word: 183 : discus appears 1 times.\n",
      "Word: 195 : extraction appears 1 times.\n",
      "Word: 196 : feature appears 2 times.\n",
      "Word: 198 : form appears 1 times.\n",
      "Word: 203 : generated appears 1 times.\n",
      "Word: 207 : however appears 1 times.\n",
      "Word: 217 : linguistic appears 1 times.\n",
      "Word: 227 : node appears 39 times.\n",
      "Word: 237 : provide appears 5 times.\n",
      "Word: 242 : relationship appears 1 times.\n",
      "Word: 247 : right appears 2 times.\n",
      "Word: 251 : second appears 2 times.\n",
      "Word: 253 : sentence appears 1 times.\n",
      "Word: 256 : shown appears 5 times.\n",
      "Word: 261 : suitable appears 1 times.\n",
      "Word: 268 : thus appears 1 times.\n",
      "Word: 289 : algorithm appears 2 times.\n",
      "Word: 292 : always appears 1 times.\n",
      "Word: 311 : complete appears 1 times.\n",
      "Word: 313 : component appears 11 times.\n",
      "Word: 323 : defined appears 1 times.\n",
      "Word: 332 : discussion appears 1 times.\n",
      "Word: 336 : eg appears 1 times.\n",
      "Word: 338 : elementary appears 14 times.\n",
      "Word: 350 : fact appears 1 times.\n",
      "Word: 352 : figure appears 1 times.\n",
      "Word: 353 : following appears 1 times.\n",
      "Word: 357 : get appears 1 times.\n",
      "Word: 358 : given appears 1 times.\n",
      "Word: 372 : indicating appears 1 times.\n",
      "Word: 387 : left appears 3 times.\n",
      "Word: 395 : might appears 1 times.\n",
      "Word: 398 : n appears 2 times.\n",
      "Word: 401 : next appears 1 times.\n",
      "Word: 404 : occur appears 1 times.\n",
      "Word: 417 : problem appears 2 times.\n",
      "Word: 424 : recognition appears 1 times.\n",
      "Word: 427 : s appears 2 times.\n",
      "Word: 429 : see appears 3 times.\n",
      "Word: 440 : standard appears 2 times.\n",
      "Word: 445 : syntactic appears 3 times.\n",
      "Word: 447 : tag appears 16 times.\n",
      "Word: 454 : the appears 1 times.\n",
      "Word: 465 : whose appears 1 times.\n",
      "Word: 466 : work appears 3 times.\n",
      "Word: 515 : derived appears 9 times.\n",
      "Word: 517 : english appears 2 times.\n",
      "Word: 524 : german appears 1 times.\n",
      "Word: 530 : like appears 1 times.\n",
      "Word: 546 : principle appears 1 times.\n",
      "Word: 552 : resulting appears 2 times.\n",
      "Word: 559 : study appears 1 times.\n",
      "Word: 579 : aspect appears 1 times.\n",
      "Word: 580 : associated appears 6 times.\n",
      "Word: 604 : earlier appears 1 times.\n",
      "Word: 614 : far appears 1 times.\n",
      "Word: 617 : give appears 1 times.\n",
      "Word: 634 : level appears 2 times.\n",
      "Word: 639 : look appears 1 times.\n",
      "Word: 640 : marked appears 1 times.\n",
      "Word: 641 : mean appears 1 times.\n",
      "Word: 642 : new appears 1 times.\n",
      "Word: 648 : part appears 1 times.\n",
      "Word: 667 : rule appears 1 times.\n",
      "Word: 669 : separated appears 1 times.\n",
      "Word: 683 : type appears 2 times.\n",
      "Word: 687 : well appears 1 times.\n",
      "Word: 688 : whereas appears 1 times.\n",
      "Word: 689 : whether appears 1 times.\n",
      "Word: 690 : within appears 3 times.\n",
      "Word: 696 : appearing appears 1 times.\n",
      "Word: 713 : composition appears 2 times.\n",
      "Word: 725 : corresponds appears 1 times.\n",
      "Word: 737 : discussed appears 3 times.\n",
      "Word: 756 : formal appears 1 times.\n",
      "Word: 762 : here appears 1 times.\n",
      "Word: 767 : i appears 1 times.\n",
      "Word: 791 : linguistically appears 1 times.\n",
      "Word: 798 : may appears 2 times.\n",
      "Word: 803 : modulo appears 1 times.\n",
      "Word: 811 : operation appears 13 times.\n",
      "Word: 822 : phrase appears 1 times.\n",
      "Word: 826 : present appears 1 times.\n",
      "Word: 827 : presented appears 1 times.\n",
      "Word: 849 : semantically appears 1 times.\n",
      "Word: 853 : single appears 1 times.\n",
      "Word: 858 : subject appears 3 times.\n",
      "Word: 860 : substituted appears 9 times.\n",
      "Word: 861 : substituting appears 3 times.\n",
      "Word: 862 : substitution appears 10 times.\n",
      "Word: 868 : treatment appears 1 times.\n",
      "Word: 869 : u appears 1 times.\n",
      "Word: 880 : verb appears 2 times.\n",
      "Word: 882 : vp appears 2 times.\n",
      "Word: 884 : way appears 1 times.\n",
      "Word: 908 : address appears 2 times.\n",
      "Word: 914 : allows appears 1 times.\n",
      "Word: 931 : called appears 4 times.\n",
      "Word: 933 : certain appears 2 times.\n",
      "Word: 940 : considered appears 1 times.\n",
      "Word: 943 : constraint appears 3 times.\n",
      "Word: 957 : desired appears 1 times.\n",
      "Word: 964 : encode appears 1 times.\n",
      "Word: 991 : including appears 1 times.\n",
      "Word: 1013 : manner appears 1 times.\n",
      "Word: 1017 : motivation appears 1 times.\n",
      "Word: 1035 : performed appears 1 times.\n",
      "Word: 1062 : remain appears 1 times.\n",
      "Word: 1063 : removed appears 1 times.\n",
      "Word: 1108 : violate appears 1 times.\n",
      "Word: 1114 : which appears 1 times.\n",
      "Word: 1123 : alternative appears 1 times.\n",
      "Word: 1125 : arises appears 1 times.\n",
      "Word: 1159 : dependency appears 4 times.\n",
      "Word: 1160 : derivation appears 14 times.\n",
      "Word: 1165 : direction appears 1 times.\n",
      "Word: 1170 : edge appears 1 times.\n",
      "Word: 1185 : finite appears 1 times.\n",
      "Word: 1189 : g appears 3 times.\n",
      "Word: 1192 : grammar appears 18 times.\n",
      "Word: 1218 : let appears 1 times.\n",
      "Word: 1219 : lexical appears 3 times.\n",
      "Word: 1230 : motivated appears 1 times.\n",
      "Word: 1234 : notion appears 1 times.\n",
      "Word: 1236 : object appears 1 times.\n",
      "Word: 1239 : ordering appears 1 times.\n",
      "Word: 1279 : say appears 1 times.\n",
      "Word: 1287 : string appears 1 times.\n",
      "Word: 1338 : briefly appears 1 times.\n",
      "Word: 1469 : phenomenon appears 2 times.\n",
      "Word: 1538 : complex appears 1 times.\n",
      "Word: 1561 : grammatical appears 1 times.\n",
      "Word: 1585 : overcome appears 1 times.\n",
      "Word: 1611 : 1988 appears 1 times.\n",
      "Word: 1612 : additional appears 1 times.\n",
      "Word: 1613 : adjoined appears 5 times.\n",
      "Word: 1614 : adjoining appears 8 times.\n",
      "Word: 1615 : adjp appears 1 times.\n",
      "Word: 1616 : adjunct appears 1 times.\n",
      "Word: 1617 : adjunction appears 6 times.\n",
      "Word: 1618 : adore appears 5 times.\n",
      "Word: 1619 : advantage appears 1 times.\n",
      "Word: 1620 : alternatively appears 1 times.\n",
      "Word: 1621 : anchor appears 2 times.\n",
      "Word: 1622 : annotate appears 1 times.\n",
      "Word: 1623 : annotation appears 1 times.\n",
      "Word: 1624 : arbitrarily appears 1 times.\n",
      "Word: 1625 : asymmetry appears 1 times.\n",
      "Word: 1626 : below appears 1 times.\n",
      "Word: 1627 : brief appears 1 times.\n",
      "Word: 1628 : checking appears 1 times.\n",
      "Word: 1629 : claim appears 7 times.\n",
      "Word: 1630 : clausal appears 4 times.\n",
      "Word: 1631 : clause appears 2 times.\n",
      "Word: 1632 : cleanly appears 1 times.\n",
      "Word: 1633 : clitics appears 1 times.\n",
      "Word: 1634 : complement appears 4 times.\n",
      "Word: 1635 : complementation appears 3 times.\n",
      "Word: 1636 : composed appears 1 times.\n",
      "Word: 1637 : conception appears 1 times.\n",
      "Word: 1638 : d appears 1 times.\n",
      "Word: 1639 : daughter appears 1 times.\n",
      "Word: 1640 : dedge appears 6 times.\n",
      "Word: 1641 : dedges appears 3 times.\n",
      "Word: 1642 : dedgesnodes appears 1 times.\n",
      "Word: 1643 : define appears 3 times.\n",
      "Word: 1644 : definition appears 2 times.\n",
      "Word: 1645 : describe appears 1 times.\n",
      "Word: 1646 : designed appears 2 times.\n",
      "Word: 1647 : distance appears 2 times.\n",
      "Word: 1648 : distinctive appears 1 times.\n",
      "Word: 1649 : distribute appears 1 times.\n",
      "Word: 1650 : dof appears 1 times.\n",
      "Word: 1651 : dominance appears 1 times.\n",
      "Word: 1652 : dominates appears 1 times.\n",
      "Word: 1653 : domination appears 2 times.\n",
      "Word: 1654 : drift appears 1 times.\n",
      "Word: 1655 : dsisteradjoined appears 1 times.\n",
      "Word: 1656 : dtg appears 13 times.\n",
      "Word: 1657 : dtree appears 20 times.\n",
      "Word: 1658 : dtrees appears 10 times.\n",
      "Word: 1659 : embedded appears 1 times.\n",
      "Word: 1660 : enforce appears 1 times.\n",
      "Word: 1661 : ensure appears 2 times.\n",
      "Word: 1662 : essential appears 1 times.\n",
      "Word: 1663 : extraposition appears 1 times.\n",
      "Word: 1664 : family appears 1 times.\n",
      "Word: 1665 : foot appears 2 times.\n",
      "Word: 1666 : formalism appears 2 times.\n",
      "Word: 1667 : frontier appears 2 times.\n",
      "Word: 1668 : furthermore appears 1 times.\n",
      "Word: 1669 : governing appears 2 times.\n",
      "Word: 1670 : grouped appears 1 times.\n",
      "Word: 1671 : handled appears 1 times.\n",
      "Word: 1672 : heterogeneous appears 1 times.\n",
      "Word: 1673 : iedge appears 1 times.\n",
      "Word: 1674 : inability appears 1 times.\n",
      "Word: 1675 : informally appears 1 times.\n",
      "Word: 1676 : inserted appears 4 times.\n",
      "Word: 1677 : inserting appears 3 times.\n",
      "Word: 1678 : interest appears 1 times.\n",
      "Word: 1679 : interspersed appears 1 times.\n",
      "Word: 1680 : introduction appears 1 times.\n",
      "Word: 1681 : involving appears 2 times.\n",
      "Word: 1682 : kashmiri appears 1 times.\n",
      "Word: 1683 : labelled appears 4 times.\n",
      "Word: 1684 : least appears 1 times.\n",
      "Word: 1685 : lexeme appears 1 times.\n",
      "Word: 1686 : lexicalizable appears 1 times.\n",
      "Word: 1687 : lexicalized appears 3 times.\n",
      "Word: 1688 : limitation appears 2 times.\n",
      "Word: 1689 : link appears 1 times.\n",
      "Word: 1690 : locality appears 1 times.\n",
      "Word: 1691 : long appears 2 times.\n",
      "Word: 1692 : longdistance appears 1 times.\n",
      "Word: 1693 : ltag appears 1 times.\n",
      "Word: 1694 : map appears 1 times.\n",
      "Word: 1695 : mark appears 1 times.\n",
      "Word: 1696 : maximal appears 2 times.\n",
      "Word: 1697 : mctag appears 2 times.\n",
      "Word: 1698 : mechanism appears 1 times.\n",
      "Word: 1699 : melcuk appears 1 times.\n",
      "Word: 1700 : merging appears 1 times.\n",
      "Word: 1701 : modification appears 2 times.\n",
      "Word: 1702 : motherdaughter appears 1 times.\n",
      "Word: 1703 : multicomponent appears 2 times.\n",
      "Word: 1704 : name appears 1 times.\n",
      "Word: 1705 : needed appears 1 times.\n",
      "Word: 1706 : nnode appears 1 times.\n",
      "Word: 1707 : nominal appears 1 times.\n",
      "Word: 1708 : notational appears 1 times.\n",
      "Word: 1709 : observe appears 1 times.\n",
      "Word: 1710 : obtaining appears 1 times.\n",
      "Word: 1711 : onto appears 1 times.\n",
      "Word: 1712 : partial appears 1 times.\n",
      "Word: 1713 : phd appears 1 times.\n",
      "Word: 1714 : phrasestructure appears 1 times.\n",
      "Word: 1715 : picturenps appears 1 times.\n",
      "Word: 1716 : placed appears 1 times.\n",
      "Word: 1717 : practice appears 1 times.\n",
      "Word: 1718 : prevents appears 1 times.\n",
      "Word: 1719 : previously appears 1 times.\n",
      "Word: 1720 : project appears 1 times.\n",
      "Word: 1721 : projection appears 4 times.\n",
      "Word: 1722 : relate appears 2 times.\n",
      "Word: 1723 : requires appears 1 times.\n",
      "Word: 1724 : romance appears 1 times.\n",
      "Word: 1725 : root appears 4 times.\n",
      "Word: 1726 : rooted appears 1 times.\n",
      "Word: 1727 : ruling appears 1 times.\n",
      "Word: 1728 : sac appears 2 times.\n",
      "Word: 1729 : said appears 1 times.\n",
      "Word: 1730 : satisfactory appears 1 times.\n",
      "Word: 1731 : satree appears 1 times.\n",
      "Word: 1732 : satrees appears 1 times.\n",
      "Word: 1733 : schabes appears 1 times.\n",
      "Word: 1734 : scrambling appears 2 times.\n",
      "Word: 1735 : seems appears 11 times.\n",
      "Word: 1736 : seen appears 1 times.\n",
      "Word: 1737 : share appears 1 times.\n",
      "Word: 1738 : shieber appears 1 times.\n",
      "Word: 1739 : sic appears 2 times.\n",
      "Word: 1740 : sics appears 2 times.\n",
      "Word: 1741 : simulates appears 1 times.\n",
      "Word: 1742 : simultaneously appears 1 times.\n",
      "Word: 1743 : sisteradjoined appears 3 times.\n",
      "Word: 1744 : sisteradjoining appears 1 times.\n",
      "Word: 1745 : sisteradjunction appears 6 times.\n",
      "Word: 1746 : sisteradjunctions appears 1 times.\n",
      "Word: 1747 : specify appears 1 times.\n",
      "Word: 1748 : subjacency appears 1 times.\n",
      "Word: 1749 : subsert appears 3 times.\n",
      "Word: 1750 : subserted appears 1 times.\n",
      "Word: 1751 : subserting appears 1 times.\n",
      "Word: 1752 : subsertion appears 5 times.\n",
      "Word: 1753 : subsertionadjoining appears 1 times.\n",
      "Word: 1754 : subsertioninsertion appears 3 times.\n",
      "Word: 1755 : substitutability appears 1 times.\n",
      "Word: 1756 : substitutable appears 2 times.\n",
      "Word: 1757 : t0g appears 1 times.\n",
      "Word: 1758 : terminal appears 2 times.\n",
      "Word: 1759 : tg appears 2 times.\n",
      "Word: 1760 : that appears 1 times.\n",
      "Word: 1761 : thesis appears 1 times.\n",
      "Word: 1762 : throughout appears 1 times.\n",
      "Word: 1763 : tig appears 1 times.\n",
      "Word: 1764 : together appears 1 times.\n",
      "Word: 1765 : top appears 1 times.\n",
      "Word: 1766 : traversal appears 1 times.\n",
      "Word: 1767 : treeadjoining appears 3 times.\n",
      "Word: 1768 : unambiguously appears 1 times.\n",
      "Word: 1769 : uniformity appears 1 times.\n",
      "Word: 1770 : univ appears 1 times.\n",
      "Word: 1771 : unlike appears 2 times.\n",
      "Word: 1772 : vpfin appears 1 times.\n",
      "Word: 1773 : whextraction appears 2 times.\n"
     ]
    }
   ],
   "source": [
    "bagOfWords10 = bagOfWords[10]\n",
    "for value in bagOfWords10:\n",
    "    print(\"Word:\",value[0],\":\",dictionary[value[0]],\"appears\",value[1],\"times.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Creating the TF-IDF Model on the BagOfWords ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "tfIdf = models.TfidfModel(bagOfWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusTfIdf = tfIdf[bagOfWords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6, 0.0063309794583893296),\n",
       " (16, 0.011099543936877992),\n",
       " (19, 0.002421228796177869),\n",
       " (20, 0.01868742373432438),\n",
       " (24, 0.015375772155766326),\n",
       " (32, 0.01239226965830445),\n",
       " (33, 0.026943624664441133),\n",
       " (34, 0.016353161128169823),\n",
       " (49, 0.03270632225633965),\n",
       " (71, 0.027612461987154727),\n",
       " (74, 0.0026723718043296864),\n",
       " (78, 0.010105509906997061),\n",
       " (86, 0.014942186141414869),\n",
       " (88, 0.0162216784318173),\n",
       " (103, 0.0036171919957734494),\n",
       " (104, 0.0045291480354023765),\n",
       " (106, 0.002470602369836127),\n",
       " (110, 0.09680144478468378),\n",
       " (114, 0.022837810655909094),\n",
       " (120, 0.004389838269311124),\n",
       " (126, 0.006831346925506218),\n",
       " (131, 0.003990769958366832),\n",
       " (132, 0.03382159122909624),\n",
       " (135, 0.0986272557919883),\n",
       " (136, 0.006727791412284012),\n",
       " (139, 0.0417156560205006),\n",
       " (143, 0.019878110868313623),\n",
       " (144, 0.0014703738091943028),\n",
       " (147, 0.001597109459641685),\n",
       " (153, 0.005044640199672259),\n",
       " (154, 0.2194466274664879),\n",
       " (155, 0.020966215222502447),\n",
       " (156, 0.022271768730860037),\n",
       " (157, 0.021773533066921084),\n",
       " (158, 0.022271768730860037),\n",
       " (159, 0.006526021977790453),\n",
       " (160, 0.02395491994347179),\n",
       " (161, 0.02513983549214459),\n",
       " (162, 0.030382607946768687),\n",
       " (163, 0.025710752013187593),\n",
       " (164, 0.015225207103939398),\n",
       " (165, 0.022271768730860037),\n",
       " (166, 0.00798224648442453),\n",
       " (167, 0.030382607946768687),\n",
       " (168, 0.056992817248107584),\n",
       " (169, 0.02395491994347179),\n",
       " (170, 0.013806230993577364),\n",
       " (171, 0.009925473124872923),\n",
       " (172, 0.009581213025102953),\n",
       " (173, 0.018512177242146783),\n",
       " (174, 0.013455582824568024),\n",
       " (175, 0.036432698245811426),\n",
       " (176, 0.010401338026238134),\n",
       " (177, 0.014942186141414869),\n",
       " (178, 0.05265437667762873),\n",
       " (179, 0.010483107611251223),\n",
       " (180, 0.012855376006593797),\n",
       " (181, 0.01731097299321102),\n",
       " (182, 0.035199825594557886),\n",
       " (183, 0.011099543936877992),\n",
       " (184, 0.030382607946768687),\n",
       " (185, 0.019899500335517465),\n",
       " (186, 0.030382607946768687),\n",
       " (187, 0.012297741520215497),\n",
       " (188, 0.012569917746072296),\n",
       " (189, 0.019162426050205905),\n",
       " (190, 0.012037666092378857),\n",
       " (191, 0.02357732223921763),\n",
       " (192, 0.019899500335517465),\n",
       " (193, 0.035199825594557886),\n",
       " (194, 0.025710752013187593),\n",
       " (195, 0.10459530298990409),\n",
       " (196, 0.005609978089081957),\n",
       " (197, 0.019899500335517465),\n",
       " (198, 0.0032095133319033496),\n",
       " (199, 0.06076521589353737),\n",
       " (200, 0.009750811385623039),\n",
       " (201, 0.004120791614942221),\n",
       " (202, 0.010105509906997061),\n",
       " (203, 0.030450414207878796),\n",
       " (204, 0.02513983549214459),\n",
       " (205, 0.07663048324306172),\n",
       " (206, 0.00865548649660551),\n",
       " (207, 0.004671855933581095),\n",
       " (208, 0.014942186141414869),\n",
       " (209, 0.061503088623065305),\n",
       " (210, 0.015466483023308978),\n",
       " (211, 0.022271768730860037),\n",
       " (212, 0.011788661119608815),\n",
       " (213, 0.030382607946768687),\n",
       " (214, 0.030382607946768687),\n",
       " (215, 0.019501622771246077),\n",
       " (216, 0.019899500335517465),\n",
       " (217, 0.017346212700559374),\n",
       " (218, 0.02395491994347179),\n",
       " (219, 0.021362913128117732),\n",
       " (220, 0.03979900067103493),\n",
       " (221, 0.030382607946768687),\n",
       " (222, 0.011740107033837197),\n",
       " (223, 0.030382607946768687),\n",
       " (224, 0.0045291480354023765),\n",
       " (225, 0.004600066888651184),\n",
       " (226, 0.004968158930770328),\n",
       " (227, 0.01731097299321102),\n",
       " (228, 0.009100059807626584),\n",
       " (229, 0.0162216784318173),\n",
       " (230, 0.10483107611251223),\n",
       " (231, 0.030382607946768687),\n",
       " (232, 0.007856419403550698),\n",
       " (233, 0.019899500335517465),\n",
       " (234, 0.011788661119608815),\n",
       " (235, 0.004186902304306846),\n",
       " (236, 0.007856419403550698),\n",
       " (237, 0.006727791412284012),\n",
       " (238, 0.008242321912261171),\n",
       " (239, 0.02395491994347179),\n",
       " (240, 0.01691079561454812),\n",
       " (241, 0.017527231940174894),\n",
       " (242, 0.027300179422879756),\n",
       " (243, 0.019162426050205905),\n",
       " (244, 0.011099543936877992),\n",
       " (245, 0.02631095883116182),\n",
       " (246, 0.910286957851928),\n",
       " (247, 0.00941639272426624),\n",
       " (248, 0.049190966080861986),\n",
       " (249, 0.030382607946768687),\n",
       " (250, 0.030382607946768687),\n",
       " (251, 0.004389838269311124),\n",
       " (252, 0.03270632225633965),\n",
       " (253, 0.08225990720892273),\n",
       " (254, 0.030382607946768687),\n",
       " (255, 0.01691079561454812),\n",
       " (256, 0.006427688003296898),\n",
       " (257, 0.007612603551969699),\n",
       " (258, 0.026327188338814363),\n",
       " (259, 0.030382607946768687),\n",
       " (260, 0.01691079561454812),\n",
       " (261, 0.01315547941558091),\n",
       " (262, 0.034772175762064955),\n",
       " (263, 0.030382607946768687),\n",
       " (264, 0.015375772155766326),\n",
       " (265, 0.011788661119608815),\n",
       " (266, 0.013873536807807165),\n",
       " (267, 0.030382607946768687),\n",
       " (268, 0.004892664544515102),\n",
       " (269, 0.0056953917776687134),\n",
       " (270, 0.01029126308797078),\n",
       " (271, 0.01029126308797078),\n",
       " (272, 0.030382607946768687),\n",
       " (273, 0.014160929514951388)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpusTfIdf[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Making LDA on Bag Of Words ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gensim/models/ldamodel.py:1023: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n"
     ]
    }
   ],
   "source": [
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "ldaBow = Lda(bagOfWords,id2word=dictionary,passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.057*\"grammar\" + 0.040*\"rule\" + 0.027*\"magic\" + 0.016*\"pruning\" + 0.012*\"constituent\" + 0.010*\"result\" + 0.009*\"specialization\" + 0.009*\"edge\" + 0.009*\"figure\" + 0.008*\"coverage\"'),\n",
       " (1,\n",
       "  '0.046*\"transition\" + 0.041*\"grammar\" + 0.021*\"model\" + 0.020*\"language\" + 0.020*\"formalism\" + 0.020*\"word\" + 0.016*\"category\" + 0.014*\"dog\" + 0.014*\"state\" + 0.012*\"corpus\"'),\n",
       " (2,\n",
       "  '0.053*\"word\" + 0.018*\"speech\" + 0.017*\"class\" + 0.014*\"corpus\" + 0.014*\"lexicon\" + 0.013*\"used\" + 0.012*\"ambiguity\" + 0.011*\"code\" + 0.010*\"suffix\" + 0.010*\"training\"'),\n",
       " (3,\n",
       "  '0.029*\"language\" + 0.021*\"word\" + 0.020*\"processing\" + 0.019*\"segment\" + 0.018*\"speech\" + 0.016*\"lexical\" + 0.016*\"recognition\" + 0.016*\"phoneme\" + 0.015*\"text\" + 0.012*\"spoken\"'),\n",
       " (4,\n",
       "  '0.028*\"colour\" + 0.025*\"equation\" + 0.025*\"solution\" + 0.024*\"rule\" + 0.024*\"variable\" + 0.022*\"occurrence\" + 0.018*\"coloured\" + 0.016*\"tgl\" + 0.014*\"primary\" + 0.014*\"set\"'),\n",
       " (5,\n",
       "  '0.029*\"lexical\" + 0.028*\"datr\" + 0.021*\"word\" + 0.017*\"theory\" + 0.014*\"function\" + 0.014*\"path\" + 0.014*\"category\" + 0.014*\"value\" + 0.013*\"information\" + 0.013*\"node\"'),\n",
       " (6,\n",
       "  '0.061*\"clause\" + 0.036*\"subordinate\" + 0.031*\"role\" + 0.029*\"main\" + 0.025*\"sentence\" + 0.022*\"agent\" + 0.018*\"semantic\" + 0.018*\"task\" + 0.017*\"complex\" + 0.017*\"constraint\"'),\n",
       " (7,\n",
       "  '0.019*\"text\" + 0.017*\"class\" + 0.015*\"system\" + 0.013*\"one\" + 0.011*\"different\" + 0.010*\"technique\" + 0.010*\"nlg\" + 0.009*\"use\" + 0.009*\"used\" + 0.008*\"number\"'),\n",
       " (8,\n",
       "  '0.073*\"rule\" + 0.027*\"spelling\" + 0.024*\"parsing\" + 0.024*\"lexical\" + 0.022*\"surface\" + 0.018*\"algorithm\" + 0.017*\"root\" + 0.015*\"tabular\" + 0.015*\"form\" + 0.014*\"pattern\"'),\n",
       " (9,\n",
       "  '0.067*\"feature\" + 0.056*\"structure\" + 0.024*\"twolevel\" + 0.021*\"morphology\" + 0.018*\"form\" + 0.016*\"rule\" + 0.016*\"grammar\" + 0.015*\"morpheme\" + 0.015*\"stem\" + 0.014*\"morphological\"'),\n",
       " (10,\n",
       "  '0.057*\"model\" + 0.049*\"language\" + 0.044*\"relation\" + 0.030*\"translation\" + 0.028*\"word\" + 0.025*\"set\" + 0.024*\"target\" + 0.021*\"source\" + 0.020*\"graph\" + 0.017*\"statistical\"'),\n",
       " (11,\n",
       "  '0.000*\"language\" + 0.000*\"sentence\" + 0.000*\"model\" + 0.000*\"word\" + 0.000*\"task\" + 0.000*\"discourse\" + 0.000*\"evaluation\" + 0.000*\"user\" + 0.000*\"lexical\" + 0.000*\"set\"'),\n",
       " (12,\n",
       "  '0.038*\"temporal\" + 0.033*\"discourse\" + 0.032*\"structure\" + 0.026*\"relation\" + 0.024*\"agent\" + 0.021*\"plan\" + 0.013*\"tense\" + 0.012*\"rhetorical\" + 0.012*\"event\" + 0.011*\"knowledge\"'),\n",
       " (13,\n",
       "  '0.083*\"operator\" + 0.073*\"presentation\" + 0.047*\"proof\" + 0.026*\"presenting\" + 0.021*\"proverb\" + 0.021*\"present\" + 0.021*\"topdown\" + 0.021*\"task\" + 0.016*\"attentional\" + 0.016*\"bottomup\"'),\n",
       " (14,\n",
       "  '0.043*\"grammar\" + 0.017*\"node\" + 0.017*\"structure\" + 0.017*\"construction\" + 0.015*\"rule\" + 0.014*\"type\" + 0.014*\"language\" + 0.014*\"tree\" + 0.012*\"lambek\" + 0.011*\"description\"'),\n",
       " (15,\n",
       "  '0.042*\"np\" + 0.040*\"discourse\" + 0.031*\"structure\" + 0.023*\"pronoun\" + 0.021*\"rhetorical\" + 0.014*\"utterance\" + 0.014*\"anaphoric\" + 0.014*\"phrasal\" + 0.013*\"sentence\" + 0.012*\"entity\"'),\n",
       " (16,\n",
       "  '0.000*\"rule\" + 0.000*\"grammar\" + 0.000*\"algorithm\" + 0.000*\"language\" + 0.000*\"parsing\" + 0.000*\"discourse\" + 0.000*\"generation\" + 0.000*\"word\" + 0.000*\"structure\" + 0.000*\"model\"'),\n",
       " (17,\n",
       "  '0.123*\"corpus\" + 0.064*\"english\" + 0.053*\"scheme\" + 0.052*\"annotation\" + 0.042*\"mapping\" + 0.032*\"tag\" + 0.027*\"tagging\" + 0.022*\"annotated\" + 0.020*\"spoken\" + 0.017*\"tagged\"'),\n",
       " (18,\n",
       "  '0.078*\"semantic\" + 0.036*\"contribution\" + 0.034*\"meaning\" + 0.027*\"linear\" + 0.025*\"scope\" + 0.024*\"structure\" + 0.024*\"syntactic\" + 0.024*\"language\" + 0.022*\"categorial\" + 0.021*\"logic\"'),\n",
       " (19,\n",
       "  '0.000*\"node\" + 0.000*\"example\" + 0.000*\"entropy\" + 0.000*\"tree\" + 0.000*\"semantic\" + 0.000*\"sentence\" + 0.000*\"language\" + 0.000*\"parse\" + 0.000*\"rule\" + 0.000*\"structure\"'),\n",
       " (20,\n",
       "  '0.094*\"context\" + 0.087*\"word\" + 0.076*\"vector\" + 0.047*\"right\" + 0.041*\"left\" + 0.018*\"tagging\" + 0.016*\"w\" + 0.012*\"generalized\" + 0.011*\"corpus\" + 0.011*\"induction\"'),\n",
       " (21,\n",
       "  '0.053*\"type\" + 0.029*\"feature\" + 0.019*\"structure\" + 0.017*\"unification\" + 0.017*\"tfs\" + 0.016*\"term\" + 0.016*\"machine\" + 0.011*\"language\" + 0.010*\"hierarchy\" + 0.010*\"grammar\"'),\n",
       " (22,\n",
       "  '0.046*\"rule\" + 0.032*\"preference\" + 0.018*\"interpretation\" + 0.017*\"example\" + 0.017*\"discourse\" + 0.013*\"french\" + 0.011*\"transfer\" + 0.010*\"pronoun\" + 0.010*\"utterance\" + 0.009*\"model\"'),\n",
       " (23,\n",
       "  '0.047*\"evaluation\" + 0.039*\"task\" + 0.035*\"assessment\" + 0.028*\"user\" + 0.026*\"technology\" + 0.024*\"data\" + 0.024*\"project\" + 0.023*\"system\" + 0.015*\"comparative\" + 0.014*\"learning\"'),\n",
       " (24,\n",
       "  '0.000*\"presupposition\" + 0.000*\"tableau\" + 0.000*\"rule\" + 0.000*\"structure\" + 0.000*\"branch\" + 0.000*\"sentence\" + 0.000*\"built\" + 0.000*\"term\" + 0.000*\"information\" + 0.000*\"example\"'),\n",
       " (25,\n",
       "  '0.106*\"phrase\" + 0.098*\"noun\" + 0.030*\"possessive\" + 0.024*\"pronoun\" + 0.022*\"number\" + 0.017*\"english\" + 0.017*\"japanese\" + 0.015*\"machine\" + 0.014*\"translation\" + 0.012*\"countability\"'),\n",
       " (26,\n",
       "  '0.053*\"presupposition\" + 0.052*\"cache\" + 0.038*\"model\" + 0.027*\"stack\" + 0.026*\"tableau\" + 0.025*\"sentence\" + 0.018*\"information\" + 0.018*\"branch\" + 0.016*\"framework\" + 0.016*\"main\"'),\n",
       " (27,\n",
       "  '0.074*\"fsa\" + 0.041*\"intersection\" + 0.039*\"grammar\" + 0.033*\"dcg\" + 0.026*\"parse\" + 0.023*\"input\" + 0.022*\"forest\" + 0.017*\"parsing\" + 0.014*\"cfg\" + 0.013*\"case\"'),\n",
       " (28,\n",
       "  '0.059*\"site\" + 0.058*\"dialect\" + 0.027*\"distance\" + 0.018*\"group\" + 0.017*\"word\" + 0.014*\"technique\" + 0.012*\"one\" + 0.011*\"phonetic\" + 0.011*\"string\" + 0.010*\"area\"'),\n",
       " (29,\n",
       "  '0.031*\"agent\" + 0.027*\"inference\" + 0.022*\"strategy\" + 0.018*\"belief\" + 0.015*\"plan\" + 0.013*\"evidence\" + 0.013*\"pragmatic\" + 0.013*\"utterance\" + 0.013*\"assumption\" + 0.011*\"model\"'),\n",
       " (30,\n",
       "  '0.100*\"word\" + 0.064*\"rule\" + 0.049*\"unknown\" + 0.033*\"lexicon\" + 0.032*\"guessing\" + 0.019*\"morphological\" + 0.017*\"tagging\" + 0.015*\"corpus\" + 0.015*\"rulesets\" + 0.015*\"guesser\"'),\n",
       " (31,\n",
       "  '0.000*\"word\" + 0.000*\"term\" + 0.000*\"lexicon\" + 0.000*\"training\" + 0.000*\"corpus\" + 0.000*\"set\" + 0.000*\"meaning\" + 0.000*\"tag\" + 0.000*\"model\" + 0.000*\"semantic\"'),\n",
       " (32,\n",
       "  '0.000*\"agent\" + 0.000*\"strategy\" + 0.000*\"task\" + 0.000*\"term\" + 0.000*\"probability\" + 0.000*\"explicitwarrant\" + 0.000*\"warrant\" + 0.000*\"feature\" + 0.000*\"reading\" + 0.000*\"tree\"'),\n",
       " (33,\n",
       "  '0.061*\"discourse\" + 0.047*\"cue\" + 0.032*\"pause\" + 0.030*\"operation\" + 0.025*\"probability\" + 0.023*\"attentional\" + 0.022*\"structure\" + 0.022*\"segment\" + 0.021*\"focus\" + 0.019*\"focusing\"'),\n",
       " (34,\n",
       "  '0.032*\"semantic\" + 0.023*\"icon\" + 0.022*\"existence\" + 0.021*\"presupposition\" + 0.012*\"logic\" + 0.012*\"model\" + 0.011*\"sentence\" + 0.011*\"natural\" + 0.011*\"utterance\" + 0.010*\"language\"'),\n",
       " (35,\n",
       "  '0.000*\"word\" + 0.000*\"interpretation\" + 0.000*\"sentence\" + 0.000*\"clause\" + 0.000*\"example\" + 0.000*\"discourse\" + 0.000*\"source\" + 0.000*\"preference\" + 0.000*\"datr\" + 0.000*\"reading\"'),\n",
       " (36,\n",
       "  '0.000*\"word\" + 0.000*\"tree\" + 0.000*\"model\" + 0.000*\"node\" + 0.000*\"decision\" + 0.000*\"description\" + 0.000*\"attachment\" + 0.000*\"accessible\" + 0.000*\"new\" + 0.000*\"treelowering\"'),\n",
       " (37,\n",
       "  '0.093*\"term\" + 0.038*\"feature\" + 0.034*\"dictionary\" + 0.027*\"prolog\" + 0.018*\"discipline\" + 0.016*\"general\" + 0.014*\"word\" + 0.013*\"used\" + 0.013*\"sl\" + 0.013*\"sorted\"'),\n",
       " (38,\n",
       "  '0.053*\"tree\" + 0.044*\"decision\" + 0.036*\"model\" + 0.034*\"sentence\" + 0.029*\"decisiontree\" + 0.027*\"parse\" + 0.017*\"question\" + 0.016*\"node\" + 0.015*\"spatter\" + 0.015*\"word\"'),\n",
       " (39,\n",
       "  '0.066*\"meaning\" + 0.058*\"semantics\" + 0.042*\"function\" + 0.028*\"verb\" + 0.025*\"compositional\" + 0.024*\"set\" + 0.021*\"language\" + 0.019*\"motion\" + 0.014*\"preposition\" + 0.014*\"natural\"'),\n",
       " (40,\n",
       "  '0.000*\"verb\" + 0.000*\"preposition\" + 0.000*\"data\" + 0.000*\"function\" + 0.000*\"motion\" + 0.000*\"training\" + 0.000*\"semantics\" + 0.000*\"test\" + 0.000*\"attachment\" + 0.000*\"method\"'),\n",
       " (41,\n",
       "  '0.039*\"parser\" + 0.036*\"pitch\" + 0.032*\"robust\" + 0.029*\"accent\" + 0.018*\"error\" + 0.018*\"sentence\" + 0.015*\"pronominal\" + 0.013*\"attentional\" + 0.013*\"accented\" + 0.013*\"algorithm\"'),\n",
       " (42,\n",
       "  '0.058*\"sign\" + 0.051*\"bag\" + 0.037*\"lexical\" + 0.030*\"outer\" + 0.030*\"dog\" + 0.029*\"domain\" + 0.029*\"generation\" + 0.028*\"brown\" + 0.028*\"generator\" + 0.023*\"barked\"'),\n",
       " (43,\n",
       "  '0.052*\"relation\" + 0.040*\"temporal\" + 0.024*\"past\" + 0.021*\"time\" + 0.021*\"passage\" + 0.017*\"planning\" + 0.016*\"simple\" + 0.014*\"ordering\" + 0.013*\"account\" + 0.012*\"explanation\"'),\n",
       " (44,\n",
       "  '0.000*\"model\" + 0.000*\"word\" + 0.000*\"tree\" + 0.000*\"data\" + 0.000*\"tag\" + 0.000*\"pragmatic\" + 0.000*\"method\" + 0.000*\"node\" + 0.000*\"using\" + 0.000*\"training\"'),\n",
       " (45,\n",
       "  '0.040*\"grammar\" + 0.038*\"sentence\" + 0.029*\"complexity\" + 0.020*\"text\" + 0.018*\"set\" + 0.016*\"number\" + 0.014*\"semantic\" + 0.014*\"analysis\" + 0.013*\"parser\" + 0.011*\"parsing\"'),\n",
       " (46,\n",
       "  '0.121*\"control\" + 0.053*\"shift\" + 0.038*\"topic\" + 0.035*\"discourse\" + 0.032*\"dialogue\" + 0.029*\"participant\" + 0.022*\"speaker\" + 0.018*\"cue\" + 0.016*\"utterance\" + 0.016*\"expert\"'),\n",
       " (47,\n",
       "  '0.000*\"type\" + 0.000*\"rule\" + 0.000*\"grammar\" + 0.000*\"corpus\" + 0.000*\"word\" + 0.000*\"function\" + 0.000*\"semantics\" + 0.000*\"lexical\" + 0.000*\"language\" + 0.000*\"tag\"'),\n",
       " (48,\n",
       "  '0.099*\"tree\" + 0.029*\"tag\" + 0.027*\"node\" + 0.024*\"lexical\" + 0.023*\"hpsg\" + 0.022*\"auxiliary\" + 0.020*\"feature\" + 0.020*\"structure\" + 0.019*\"grammar\" + 0.019*\"verb\"'),\n",
       " (49,\n",
       "  '0.071*\"nonmonotonic\" + 0.066*\"term\" + 0.057*\"rule\" + 0.024*\"default\" + 0.021*\"sort\" + 0.020*\"acquisition\" + 0.016*\"variant\" + 0.012*\"coordination\" + 0.012*\"candidate\" + 0.010*\"one\"'),\n",
       " (50,\n",
       "  '0.026*\"discourse\" + 0.026*\"pronoun\" + 0.022*\"centering\" + 0.020*\"constraint\" + 0.017*\"utterance\" + 0.012*\"realized\" + 0.012*\"proposed\" + 0.011*\"interpretation\" + 0.011*\"entity\" + 0.011*\"algorithm\"'),\n",
       " (51,\n",
       "  '0.049*\"focus\" + 0.022*\"auxiliary\" + 0.021*\"semantic\" + 0.017*\"approach\" + 0.016*\"structure\" + 0.016*\"representation\" + 0.015*\"operator\" + 0.015*\"analysis\" + 0.014*\"genitive\" + 0.013*\"multiple\"'),\n",
       " (52,\n",
       "  '0.000*\"word\" + 0.000*\"rule\" + 0.000*\"noun\" + 0.000*\"set\" + 0.000*\"language\" + 0.000*\"constraint\" + 0.000*\"verb\" + 0.000*\"two\" + 0.000*\"corpus\" + 0.000*\"one\"'),\n",
       " (53,\n",
       "  '0.043*\"function\" + 0.031*\"score\" + 0.026*\"sentence\" + 0.025*\"analysis\" + 0.024*\"qlf\" + 0.021*\"preference\" + 0.019*\"factor\" + 0.019*\"language\" + 0.018*\"hypothesis\" + 0.018*\"linguistic\"'),\n",
       " (54,\n",
       "  '0.042*\"category\" + 0.033*\"left\" + 0.031*\"pitch\" + 0.030*\"accent\" + 0.028*\"example\" + 0.021*\"response\" + 0.021*\"intonation\" + 0.018*\"thoracostomy\" + 0.017*\"rule\" + 0.016*\"thoracotomy\"'),\n",
       " (55,\n",
       "  '0.000*\"model\" + 0.000*\"sentence\" + 0.000*\"language\" + 0.000*\"structure\" + 0.000*\"relation\" + 0.000*\"belief\" + 0.000*\"rhetorical\" + 0.000*\"focus\" + 0.000*\"word\" + 0.000*\"discourse\"'),\n",
       " (56,\n",
       "  '0.029*\"clause\" + 0.024*\"tncb\" + 0.019*\"generation\" + 0.017*\"goal\" + 0.016*\"item\" + 0.014*\"sign\" + 0.011*\"algorithm\" + 0.010*\"chart\" + 0.010*\"node\" + 0.009*\"target\"'),\n",
       " (57,\n",
       "  '0.020*\"rule\" + 0.018*\"attributevalue\" + 0.017*\"event\" + 0.015*\"set\" + 0.014*\"grammar\" + 0.014*\"jack\" + 0.012*\"ravg\" + 0.010*\"second\" + 0.010*\"language\" + 0.010*\"syntactic\"'),\n",
       " (58,\n",
       "  '0.035*\"rule\" + 0.028*\"semantic\" + 0.014*\"use\" + 0.014*\"theory\" + 0.014*\"language\" + 0.014*\"syntax\" + 0.014*\"logic\" + 0.014*\"composition\" + 0.014*\"coordination\" + 0.014*\"ccg\"'),\n",
       " (59,\n",
       "  '0.050*\"tag\" + 0.034*\"corpus\" + 0.024*\"tagging\" + 0.024*\"word\" + 0.020*\"training\" + 0.017*\"probability\" + 0.016*\"tagset\" + 0.016*\"accuracy\" + 0.015*\"tree\" + 0.015*\"tagger\"'),\n",
       " (60,\n",
       "  '0.069*\"model\" + 0.031*\"sentence\" + 0.025*\"state\" + 0.024*\"discourse\" + 0.021*\"merging\" + 0.020*\"word\" + 0.019*\"par\" + 0.018*\"probability\" + 0.017*\"information\" + 0.015*\"parse\"'),\n",
       " (61,\n",
       "  '0.110*\"algorithm\" + 0.034*\"discourse\" + 0.028*\"hobbs\" + 0.022*\"bfp\" + 0.015*\"entity\" + 0.015*\"structure\" + 0.014*\"example\" + 0.012*\"focusing\" + 0.011*\"get\" + 0.011*\"pronoun\"'),\n",
       " (62,\n",
       "  '0.076*\"cluster\" + 0.075*\"clustering\" + 0.044*\"model\" + 0.031*\"language\" + 0.028*\"word\" + 0.024*\"clustered\" + 0.024*\"sentence\" + 0.023*\"training\" + 0.023*\"corpus\" + 0.019*\"algorithm\"'),\n",
       " (63,\n",
       "  '0.058*\"translation\" + 0.034*\"machine\" + 0.033*\"japanese\" + 0.030*\"expression\" + 0.028*\"method\" + 0.024*\"meaning\" + 0.022*\"word\" + 0.020*\"language\" + 0.017*\"japanesetoenglish\" + 0.016*\"based\"'),\n",
       " (64,\n",
       "  '0.073*\"rule\" + 0.024*\"grammar\" + 0.021*\"sentence\" + 0.014*\"chunk\" + 0.011*\"generic\" + 0.010*\"order\" + 0.010*\"word\" + 0.010*\"input\" + 0.009*\"structure\" + 0.008*\"parsing\"'),\n",
       " (65,\n",
       "  '0.032*\"discovery\" + 0.032*\"tree\" + 0.023*\"structure\" + 0.023*\"feature\" + 0.016*\"grammar\" + 0.013*\"linguistic\" + 0.011*\"set\" + 0.010*\"process\" + 0.010*\"effect\" + 0.010*\"method\"'),\n",
       " (66,\n",
       "  '0.033*\"interpretation\" + 0.028*\"sentence\" + 0.017*\"reading\" + 0.016*\"clause\" + 0.015*\"ambiguity\" + 0.014*\"source\" + 0.012*\"ellipsis\" + 0.011*\"example\" + 0.011*\"analysis\" + 0.010*\"expression\"'),\n",
       " (67,\n",
       "  '0.026*\"text\" + 0.022*\"vehicle\" + 0.014*\"action\" + 0.012*\"agent\" + 0.012*\"plan\" + 0.011*\"obligation\" + 0.010*\"car\" + 0.010*\"two\" + 0.010*\"goal\" + 0.010*\"type\"'),\n",
       " (68,\n",
       "  '0.000*\"rule\" + 0.000*\"semantic\" + 0.000*\"language\" + 0.000*\"plan\" + 0.000*\"agent\" + 0.000*\"relation\" + 0.000*\"ellipsis\" + 0.000*\"constraint\" + 0.000*\"expression\" + 0.000*\"clause\"'),\n",
       " (69,\n",
       "  '0.000*\"word\" + 0.000*\"term\" + 0.000*\"tag\" + 0.000*\"system\" + 0.000*\"accuracy\" + 0.000*\"evaluation\" + 0.000*\"corpus\" + 0.000*\"unknown\" + 0.000*\"rule\" + 0.000*\"task\"'),\n",
       " (70,\n",
       "  '0.082*\"punctuation\" + 0.060*\"grammar\" + 0.051*\"mark\" + 0.035*\"sentence\" + 0.030*\"punctuated\" + 0.027*\"unpunctuated\" + 0.018*\"lexical\" + 0.016*\"expression\" + 0.016*\"use\" + 0.015*\"par\"'),\n",
       " (71,\n",
       "  '0.020*\"message\" + 0.018*\"grammar\" + 0.018*\"dependency\" + 0.015*\"categorial\" + 0.014*\"calculus\" + 0.014*\"structure\" + 0.012*\"formula\" + 0.011*\"rule\" + 0.009*\"proof\" + 0.009*\"information\"'),\n",
       " (72,\n",
       "  '0.000*\"word\" + 0.000*\"rule\" + 0.000*\"language\" + 0.000*\"temporal\" + 0.000*\"grammar\" + 0.000*\"sentence\" + 0.000*\"speech\" + 0.000*\"structure\" + 0.000*\"example\" + 0.000*\"model\"'),\n",
       " (73,\n",
       "  '0.082*\"case\" + 0.045*\"slot\" + 0.041*\"frame\" + 0.038*\"data\" + 0.036*\"model\" + 0.028*\"dependency\" + 0.024*\"method\" + 0.022*\"pattern\" + 0.016*\"based\" + 0.012*\"learning\"'),\n",
       " (74,\n",
       "  '0.056*\"grammar\" + 0.018*\"parser\" + 0.015*\"parsing\" + 0.013*\"rule\" + 0.013*\"structure\" + 0.012*\"parse\" + 0.011*\"coordination\" + 0.009*\"sentence\" + 0.009*\"parallel\" + 0.009*\"argument\"'),\n",
       " (75,\n",
       "  '0.000*\"language\" + 0.000*\"sentence\" + 0.000*\"evaluation\" + 0.000*\"case\" + 0.000*\"translation\" + 0.000*\"source\" + 0.000*\"pronoun\" + 0.000*\"phrase\" + 0.000*\"example\" + 0.000*\"interpretation\"'),\n",
       " (76,\n",
       "  '0.000*\"grammar\" + 0.000*\"tree\" + 0.000*\"feature\" + 0.000*\"structure\" + 0.000*\"rule\" + 0.000*\"set\" + 0.000*\"parsing\" + 0.000*\"unificationbased\" + 0.000*\"constraint\" + 0.000*\"parser\"'),\n",
       " (77,\n",
       "  '0.097*\"collocation\" + 0.051*\"verb\" + 0.034*\"combination\" + 0.028*\"extracted\" + 0.027*\"vn\" + 0.027*\"precision\" + 0.027*\"word\" + 0.026*\"corpus\" + 0.021*\"noun\" + 0.020*\"extraction\"'),\n",
       " (78,\n",
       "  '0.046*\"input\" + 0.041*\"parse\" + 0.038*\"sentence\" + 0.034*\"word\" + 0.033*\"par\" + 0.031*\"heuristic\" + 0.024*\"parser\" + 0.017*\"feature\" + 0.014*\"evaluation\" + 0.014*\"skipping\"'),\n",
       " (79,\n",
       "  '0.128*\"word\" + 0.064*\"vector\" + 0.056*\"cooccurrence\" + 0.043*\"distance\" + 0.024*\"using\" + 0.022*\"disambiguation\" + 0.016*\"similarity\" + 0.014*\"english\" + 0.012*\"sense\" + 0.012*\"dictionary\"'),\n",
       " (80,\n",
       "  '0.071*\"constraint\" + 0.032*\"ellipsis\" + 0.026*\"antecedent\" + 0.024*\"term\" + 0.019*\"type\" + 0.014*\"substitution\" + 0.014*\"variable\" + 0.013*\"set\" + 0.011*\"index\" + 0.009*\"language\"'),\n",
       " (81,\n",
       "  '0.044*\"theory\" + 0.043*\"feature\" + 0.041*\"grammar\" + 0.036*\"unification\" + 0.023*\"problem\" + 0.020*\"complexity\" + 0.012*\"section\" + 0.012*\"string\" + 0.012*\"neural\" + 0.012*\"net\"'),\n",
       " (82,\n",
       "  '0.077*\"meaning\" + 0.029*\"fstructure\" + 0.020*\"semantic\" + 0.018*\"verb\" + 0.018*\"logic\" + 0.018*\"intensional\" + 0.018*\"seek\" + 0.018*\"lexical\" + 0.015*\"fstructures\" + 0.015*\"constructor\"'),\n",
       " (83,\n",
       "  '0.068*\"belief\" + 0.032*\"proposed\" + 0.030*\"model\" + 0.030*\"user\" + 0.023*\"action\" + 0.022*\"agent\" + 0.022*\"evidence\" + 0.020*\"system\" + 0.018*\"collaborative\" + 0.014*\"german\"'),\n",
       " (84,\n",
       "  '0.056*\"tree\" + 0.042*\"derivation\" + 0.032*\"synchronous\" + 0.028*\"tone\" + 0.027*\"tag\" + 0.022*\"pair\" + 0.022*\"transcription\" + 0.019*\"definition\" + 0.018*\"sequence\" + 0.017*\"program\"'),\n",
       " (85,\n",
       "  '0.047*\"lfg\" + 0.043*\"coreference\" + 0.042*\"phrase\" + 0.039*\"feature\" + 0.028*\"fstructure\" + 0.028*\"rule\" + 0.027*\"information\" + 0.020*\"tree\" + 0.019*\"muc5\" + 0.018*\"coreferent\"'),\n",
       " (86,\n",
       "  '0.023*\"gapping\" + 0.022*\"inference\" + 0.022*\"vpellipsis\" + 0.020*\"representation\" + 0.020*\"form\" + 0.019*\"example\" + 0.018*\"discourse\" + 0.017*\"coherent\" + 0.016*\"construction\" + 0.016*\"semantic\"'),\n",
       " (87,\n",
       "  '0.061*\"grammar\" + 0.030*\"algorithm\" + 0.030*\"data\" + 0.026*\"model\" + 0.024*\"tagset\" + 0.023*\"rule\" + 0.021*\"insideoutside\" + 0.020*\"training\" + 0.019*\"language\" + 0.016*\"ngram\"'),\n",
       " (88,\n",
       "  '0.096*\"model\" + 0.071*\"probability\" + 0.056*\"bigram\" + 0.049*\"estimate\" + 0.037*\"word\" + 0.033*\"unseen\" + 0.028*\"similarity\" + 0.027*\"similaritybased\" + 0.019*\"backoff\" + 0.017*\"language\"'),\n",
       " (89,\n",
       "  '0.128*\"expression\" + 0.123*\"referring\" + 0.115*\"generation\" + 0.067*\"referent\" + 0.038*\"hearer\" + 0.036*\"language\" + 0.033*\"natural\" + 0.028*\"identification\" + 0.021*\"intended\" + 0.020*\"description\"'),\n",
       " (90,\n",
       "  '0.016*\"bracketings\" + 0.016*\"dcglike\" + 0.016*\"manuallydisambiguated\" + 0.015*\"choice\" + 0.014*\"likely\" + 0.008*\"post\" + 0.008*\"7080\" + 0.008*\"400\" + 0.008*\"posing\" + 0.008*\"parsertreebank\"'),\n",
       " (91,\n",
       "  '0.045*\"verb\" + 0.029*\"word\" + 0.024*\"construction\" + 0.022*\"noun\" + 0.022*\"information\" + 0.017*\"similarity\" + 0.013*\"semantic\" + 0.009*\"concept\" + 0.009*\"form\" + 0.008*\"taxonomy\"'),\n",
       " (92,\n",
       "  '0.048*\"training\" + 0.036*\"data\" + 0.019*\"word\" + 0.019*\"bin\" + 0.016*\"model\" + 0.016*\"noun\" + 0.014*\"statistical\" + 0.014*\"compound\" + 0.014*\"set\" + 0.013*\"instance\"'),\n",
       " (93,\n",
       "  '0.032*\"cluster\" + 0.031*\"entropy\" + 0.030*\"model\" + 0.021*\"data\" + 0.019*\"node\" + 0.017*\"set\" + 0.016*\"distribution\" + 0.016*\"tree\" + 0.015*\"clustering\" + 0.014*\"noun\"'),\n",
       " (94,\n",
       "  '0.041*\"word\" + 0.020*\"language\" + 0.020*\"semantic\" + 0.017*\"representation\" + 0.017*\"sentence\" + 0.016*\"grammar\" + 0.014*\"syntactic\" + 0.013*\"interpretation\" + 0.012*\"model\" + 0.012*\"semantics\"'),\n",
       " (95,\n",
       "  '0.037*\"language\" + 0.029*\"tree\" + 0.027*\"node\" + 0.024*\"set\" + 0.021*\"theory\" + 0.017*\"structure\" + 0.014*\"complexity\" + 0.013*\"class\" + 0.012*\"grammar\" + 0.009*\"chain\"'),\n",
       " (96,\n",
       "  '0.000*\"rule\" + 0.000*\"word\" + 0.000*\"grammar\" + 0.000*\"language\" + 0.000*\"model\" + 0.000*\"set\" + 0.000*\"input\" + 0.000*\"relation\" + 0.000*\"tree\" + 0.000*\"form\"'),\n",
       " (97,\n",
       "  '0.000*\"algorithm\" + 0.000*\"parsing\" + 0.000*\"tabular\" + 0.000*\"lr\" + 0.000*\"model\" + 0.000*\"grammar\" + 0.000*\"discourse\" + 0.000*\"default\" + 0.000*\"input\" + 0.000*\"number\"'),\n",
       " (98,\n",
       "  '0.041*\"feature\" + 0.030*\"structure\" + 0.027*\"entry\" + 0.024*\"rule\" + 0.016*\"node\" + 0.016*\"lexical\" + 0.016*\"type\" + 0.016*\"lemma\" + 0.015*\"probability\" + 0.015*\"allomorph\"'),\n",
       " (99,\n",
       "  '0.000*\"function\" + 0.000*\"set\" + 0.000*\"language\" + 0.000*\"value\" + 0.000*\"sentence\" + 0.000*\"datr\" + 0.000*\"discovery\" + 0.000*\"path\" + 0.000*\"semantics\" + 0.000*\"grammar\"')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaBow.print_topics(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Making LDA on Tf-Idf Values ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldaTfIdf = Lda(corpusTfIdf,id2word=dictionary,passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.000*\"unprompted\" + 0.000*\"webber\" + 0.000*\"subgoals\" + 0.000*\"subordination\" + 0.000*\"tannen\" + 0.000*\"tod\" + 0.000*\"transferred\" + 0.000*\"uh\" + 0.000*\"started\" + 0.000*\"contextdependence\"'),\n",
       " (1,\n",
       "  '0.007*\"structural\" + 0.006*\"operation\" + 0.006*\"current\" + 0.006*\"disambiguation\" + 0.005*\"lhip\" + 0.005*\"pause\" + 0.004*\"island\" + 0.004*\"seems\" + 0.003*\"constraintbased\" + 0.003*\"focusing\"'),\n",
       " (2,\n",
       "  '0.000*\"unprompted\" + 0.000*\"webber\" + 0.000*\"subgoals\" + 0.000*\"subordination\" + 0.000*\"tannen\" + 0.000*\"tod\" + 0.000*\"transferred\" + 0.000*\"uh\" + 0.000*\"started\" + 0.000*\"contextdependence\"'),\n",
       " (3,\n",
       "  '0.005*\"auxiliary\" + 0.005*\"foot\" + 0.005*\"domination\" + 0.004*\"sfs\" + 0.004*\"hpsg\" + 0.002*\"lexicalized\" + 0.002*\"link\" + 0.001*\"schema\" + 0.001*\"raised\" + 0.001*\"anchored\"'),\n",
       " (4,\n",
       "  '0.007*\"tone\" + 0.005*\"pragmatic\" + 0.005*\"inheritance\" + 0.005*\"defeasible\" + 0.004*\"transcription\" + 0.004*\"dimension\" + 0.004*\"inference\" + 0.003*\"typed\" + 0.003*\"presupposition\" + 0.003*\"multidimensional\"'),\n",
       " (5,\n",
       "  '0.009*\"bin\" + 0.002*\"optimal\" + 0.001*\"uniform\" + 0.001*\"learner\" + 0.001*\"modebased\" + 0.001*\"falling\" + 0.001*\"arrive\" + 0.000*\"logarithmic\" + 0.000*\"itai\" + 0.000*\"severe\"'),\n",
       " (6,\n",
       "  '0.005*\"attachment\" + 0.004*\"backedoff\" + 0.003*\"underspecified\" + 0.003*\"htype\" + 0.002*\"sparse\" + 0.002*\"prepositional\" + 0.002*\"ibm\" + 0.001*\"3097\" + 0.001*\"board\" + 0.001*\"director\"'),\n",
       " (7,\n",
       "  '0.007*\"obligation\" + 0.002*\"actor\" + 0.001*\"conversation\" + 0.001*\"request\" + 0.001*\"game\" + 0.001*\"do\" + 0.001*\"govern\" + 0.001*\"suggestion\" + 0.000*\"executable\" + 0.000*\"repairing\"'),\n",
       " (8,\n",
       "  '0.000*\"unprompted\" + 0.000*\"webber\" + 0.000*\"subgoals\" + 0.000*\"subordination\" + 0.000*\"tannen\" + 0.000*\"tod\" + 0.000*\"transferred\" + 0.000*\"uh\" + 0.000*\"started\" + 0.000*\"contextdependence\"'),\n",
       " (9,\n",
       "  '0.004*\"nonunit\" + 0.003*\"earley\" + 0.003*\"goal\" + 0.002*\"deduction\" + 0.002*\"bias\" + 0.002*\"indexing\" + 0.002*\"scanning\" + 0.002*\"disambiguation\" + 0.001*\"base\" + 0.001*\"pretagged\"'),\n",
       " (10,\n",
       "  '0.000*\"unprompted\" + 0.000*\"webber\" + 0.000*\"subgoals\" + 0.000*\"subordination\" + 0.000*\"tannen\" + 0.000*\"tod\" + 0.000*\"transferred\" + 0.000*\"uh\" + 0.000*\"started\" + 0.000*\"contextdependence\"'),\n",
       " (11,\n",
       "  '0.000*\"unprompted\" + 0.000*\"webber\" + 0.000*\"subgoals\" + 0.000*\"subordination\" + 0.000*\"tannen\" + 0.000*\"tod\" + 0.000*\"transferred\" + 0.000*\"uh\" + 0.000*\"started\" + 0.000*\"contextdependence\"'),\n",
       " (12,\n",
       "  '0.003*\"verbobject\" + 0.001*\"fml\" + 0.001*\"unrestricted\" + 0.001*\"y\" + 0.001*\"hermann\" + 0.001*\"reinhard\" + 0.001*\"1and\" + 0.001*\"maximization\" + 0.001*\"redistributed\" + 0.001*\"selforganized\"'),\n",
       " (13,\n",
       "  '0.005*\"calculus\" + 0.005*\"parallel\" + 0.003*\"theorem\" + 0.003*\"suffix\" + 0.002*\"alteration\" + 0.002*\"parallelism\" + 0.002*\"ruleset\" + 0.002*\"lke\" + 0.002*\"datalog\" + 0.002*\"cascading\"'),\n",
       " (14,\n",
       "  '0.006*\"unknown\" + 0.004*\"snipe\" + 0.003*\"eats\" + 0.003*\"meat\" + 0.003*\"disjunct\" + 0.002*\"disjuncts\" + 0.002*\"link\" + 0.002*\"o\" + 0.001*\"connector\" + 0.001*\"metarule\"'),\n",
       " (15,\n",
       "  '0.005*\"chain\" + 0.005*\"nonterminal\" + 0.004*\"gb\" + 0.004*\"definable\" + 0.004*\"secondorder\" + 0.004*\"monadic\" + 0.003*\"licensed\" + 0.003*\"equivalence\" + 0.003*\"trace\" + 0.003*\"partition\"'),\n",
       " (16,\n",
       "  '0.000*\"unprompted\" + 0.000*\"webber\" + 0.000*\"subgoals\" + 0.000*\"subordination\" + 0.000*\"tannen\" + 0.000*\"tod\" + 0.000*\"transferred\" + 0.000*\"uh\" + 0.000*\"started\" + 0.000*\"contextdependence\"'),\n",
       " (17,\n",
       "  '0.021*\"tag\" + 0.016*\"probability\" + 0.012*\"tagging\" + 0.011*\"tagset\" + 0.011*\"categorial\" + 0.009*\"tagger\" + 0.009*\"morphological\" + 0.007*\"coordination\" + 0.007*\"approach\" + 0.007*\"state\"'),\n",
       " (18,\n",
       "  '0.008*\"fsa\" + 0.006*\"ks\" + 0.005*\"ltag\" + 0.004*\"datr\" + 0.004*\"inheritance\" + 0.004*\"intersection\" + 0.003*\"dcg\" + 0.002*\"discrimination\" + 0.002*\"inherit\" + 0.002*\"inherits\"'),\n",
       " (19,\n",
       "  '0.006*\"theta\" + 0.004*\"principlebased\" + 0.004*\"xbar\" + 0.003*\"commonsense\" + 0.002*\"grid\" + 0.001*\"subsystem\" + 0.001*\"parallelism\" + 0.001*\"indefeasible\" + 0.001*\"lf\" + 0.001*\"preferential\"'),\n",
       " (20,\n",
       "  '0.008*\"vector\" + 0.004*\"distance\" + 0.001*\"20m\" + 0.001*\"disambiguation\" + 0.001*\"wsd\" + 0.001*\"advantageous\" + 0.001*\"collins\" + 0.001*\"wsj\" + 0.001*\"serious\" + 0.001*\"interword\"'),\n",
       " (21,\n",
       "  '0.007*\"kanzi\" + 0.004*\"collocation\" + 0.004*\"compound\" + 0.003*\"character\" + 0.003*\"thesaurus\" + 0.001*\"collocational\" + 0.001*\"analyze\" + 0.001*\"five\" + 0.001*\"calculate\" + 0.000*\"segmented\"'),\n",
       " (22,\n",
       "  '0.009*\"presupposition\" + 0.004*\"tableau\" + 0.002*\"branch\" + 0.002*\"presuppositional\" + 0.001*\"behaviour\" + 0.001*\"compositionality\" + 0.001*\"proposition\" + 0.001*\"expansion\" + 0.001*\"presuppose\" + 0.001*\"negated\"'),\n",
       " (23,\n",
       "  '0.014*\"verb\" + 0.011*\"parsing\" + 0.010*\"input\" + 0.008*\"type\" + 0.008*\"source\" + 0.008*\"representation\" + 0.008*\"default\" + 0.007*\"information\" + 0.007*\"vehicle\" + 0.006*\"description\"'),\n",
       " (24,\n",
       "  '0.009*\"chunk\" + 0.007*\"tgl\" + 0.007*\"compound\" + 0.003*\"adjacency\" + 0.002*\"chunking\" + 0.002*\"leftbranching\" + 0.002*\"template\" + 0.002*\"gil\" + 0.002*\"window\" + 0.002*\"basenp\"'),\n",
       " (25,\n",
       "  '0.009*\"magic\" + 0.004*\"centroid\" + 0.004*\"cle\" + 0.004*\"upstream\" + 0.003*\"error\" + 0.003*\"membership\" + 0.003*\"translator\" + 0.003*\"rayner\" + 0.002*\"entropy\" + 0.002*\"rate\"'),\n",
       " (26,\n",
       "  '0.006*\"insideoutside\" + 0.003*\"ngram\" + 0.002*\"induction\" + 0.001*\"classbased\" + 0.001*\"viterbi\" + 0.001*\"syntacticrelationship\" + 0.001*\"abstraction\" + 0.001*\"mediumsized\" + 0.001*\"postpass\" + 0.001*\"vastly\"'),\n",
       " (27,\n",
       "  '0.006*\"lcp\" + 0.004*\"existence\" + 0.004*\"presupposition\" + 0.004*\"commitment\" + 0.003*\"stratified\" + 0.003*\"existential\" + 0.002*\"optimistic\" + 0.002*\"nonexistence\" + 0.002*\"valley\" + 0.002*\"cohesiveness\"'),\n",
       " (28,\n",
       "  '0.000*\"unprompted\" + 0.000*\"webber\" + 0.000*\"subgoals\" + 0.000*\"subordination\" + 0.000*\"tannen\" + 0.000*\"tod\" + 0.000*\"transferred\" + 0.000*\"uh\" + 0.000*\"started\" + 0.000*\"contextdependence\"'),\n",
       " (29,\n",
       "  '0.002*\"losing\" + 0.002*\"maximize\" + 0.001*\"restored\" + 0.001*\"pgylxk\" + 0.001*\"reducing\" + 0.001*\"logarithm\" + 0.001*\"obtain\" + 0.001*\"jjrjjt\" + 0.001*\"424\" + 0.001*\"157000\"'),\n",
       " (30,\n",
       "  '0.000*\"unprompted\" + 0.000*\"webber\" + 0.000*\"subgoals\" + 0.000*\"subordination\" + 0.000*\"tannen\" + 0.000*\"tod\" + 0.000*\"transferred\" + 0.000*\"uh\" + 0.000*\"started\" + 0.000*\"contextdependence\"'),\n",
       " (31,\n",
       "  '0.009*\"bigram\" + 0.006*\"spelling\" + 0.005*\"net\" + 0.005*\"neural\" + 0.005*\"similaritybased\" + 0.004*\"affix\" + 0.003*\"backoff\" + 0.002*\"conditional\" + 0.002*\"obligatory\" + 0.002*\"classbased\"'),\n",
       " (32,\n",
       "  '0.006*\"assessment\" + 0.006*\"focus\" + 0.005*\"robust\" + 0.004*\"hou\" + 0.003*\"extragrammatical\" + 0.003*\"parser\" + 0.003*\"technology\" + 0.003*\"higherorder\" + 0.003*\"comparative\" + 0.003*\"fsv\"'),\n",
       " (33,\n",
       "  '0.006*\"pitch\" + 0.006*\"wo\" + 0.005*\"accent\" + 0.005*\"par\" + 0.003*\"pronominal\" + 0.003*\"ordering\" + 0.003*\"accented\" + 0.002*\"incomplete\" + 0.002*\"efog\" + 0.002*\"salience\"'),\n",
       " (34,\n",
       "  '0.003*\"bel\" + 0.003*\"adjunct\" + 0.001*\"year\" + 0.001*\"ibm\" + 0.001*\"toplevel\" + 0.001*\"dash\" + 0.001*\"subcategorisation\" + 0.001*\"robust\" + 0.001*\"onsabbaticalsmithnext\" + 0.001*\"accepted\"'),\n",
       " (35,\n",
       "  '0.006*\"calculus\" + 0.006*\"iff\" + 0.006*\"lambek\" + 0.005*\"dousha\" + 0.004*\"satisfiable\" + 0.004*\"physical\" + 0.003*\"manually\" + 0.003*\"resolution\" + 0.003*\"annotation\" + 0.003*\"permutation\"'),\n",
       " (36,\n",
       "  '0.007*\"control\" + 0.007*\"shift\" + 0.005*\"topic\" + 0.004*\"dialogue\" + 0.003*\"prompt\" + 0.003*\"speaker\" + 0.002*\"interruption\" + 0.002*\"listener\" + 0.002*\"client\" + 0.001*\"summary\"'),\n",
       " (37,\n",
       "  '0.006*\"unknown\" + 0.005*\"tagsets\" + 0.003*\"swedish\" + 0.003*\"substitution\" + 0.001*\"substitutional\" + 0.001*\"criterion\" + 0.001*\"conclusion\" + 0.001*\"substitute\" + 0.001*\"metavariables\" + 0.001*\"external\"'),\n",
       " (38,\n",
       "  '0.000*\"unprompted\" + 0.000*\"webber\" + 0.000*\"subgoals\" + 0.000*\"subordination\" + 0.000*\"tannen\" + 0.000*\"tod\" + 0.000*\"transferred\" + 0.000*\"uh\" + 0.000*\"started\" + 0.000*\"contextdependence\"'),\n",
       " (39,\n",
       "  '0.004*\"fstructures\" + 0.004*\"concurrent\" + 0.003*\"coordinated\" + 0.003*\"polymorphic\" + 0.003*\"constructor\" + 0.003*\"subsumption\" + 0.003*\"weak\" + 0.002*\"intensional\" + 0.002*\"semiunification\" + 0.002*\"symposium\"'),\n",
       " (40,\n",
       "  '0.012*\"nlg\" + 0.005*\"planning\" + 0.003*\"text\" + 0.003*\"textplanning\" + 0.002*\"determination\" + 0.002*\"template\" + 0.002*\"blood\" + 0.002*\"fluent\" + 0.002*\"content\" + 0.001*\"naturallanguage\"'),\n",
       " (41,\n",
       "  '0.007*\"collocate\" + 0.004*\"collocation\" + 0.002*\"collocational\" + 0.002*\"heavy\" + 0.002*\"smoker\" + 0.002*\"collocates\" + 0.001*\"lf\" + 0.001*\"paraphrasing\" + 0.001*\"lexeme\" + 0.001*\"melcuk\"'),\n",
       " (42,\n",
       "  '0.006*\"bod\" + 0.004*\"dop\" + 0.003*\"stsg\" + 0.002*\"pcfg\" + 0.002*\"isomorphic\" + 0.001*\"exponentially\" + 0.001*\"stochastic\" + 0.001*\"schabes\" + 0.001*\"carlo\" + 0.001*\"subderivation\"'),\n",
       " (43,\n",
       "  '0.005*\"dtree\" + 0.004*\"x2morf\" + 0.004*\"phrasal\" + 0.003*\"dtg\" + 0.003*\"anaphoric\" + 0.003*\"morphology\" + 0.003*\"twolevel\" + 0.003*\"integration\" + 0.003*\"dtrees\" + 0.002*\"wordlevel\"'),\n",
       " (44,\n",
       "  '0.000*\"unprompted\" + 0.000*\"webber\" + 0.000*\"subgoals\" + 0.000*\"subordination\" + 0.000*\"tannen\" + 0.000*\"tod\" + 0.000*\"transferred\" + 0.000*\"uh\" + 0.000*\"started\" + 0.000*\"contextdependence\"'),\n",
       " (45,\n",
       "  '0.006*\"scaling\" + 0.002*\"collocation\" + 0.002*\"skeletal\" + 0.001*\"relativised\" + 0.001*\"leastsquares\" + 0.001*\"square\" + 0.001*\"calculation\" + 0.001*\"five\" + 0.001*\"collocational\" + 0.001*\"unscaled\"'),\n",
       " (46,\n",
       "  '0.008*\"datr\" + 0.003*\"descriptor\" + 0.002*\"datrs\" + 0.001*\"definitional\" + 0.001*\"valuespaths\" + 0.001*\"nodepath\" + 0.001*\"atom\" + 0.001*\"evaluable\" + 0.001*\"globally\" + 0.000*\"transparent\"'),\n",
       " (47,\n",
       "  '0.019*\"word\" + 0.018*\"rule\" + 0.016*\"training\" + 0.016*\"corpus\" + 0.012*\"cluster\" + 0.012*\"data\" + 0.011*\"class\" + 0.010*\"clustering\" + 0.008*\"translation\" + 0.008*\"logic\"'),\n",
       " (48,\n",
       "  '0.004*\"lemma\" + 0.004*\"programming\" + 0.003*\"ccg\" + 0.003*\"higherorder\" + 0.003*\"miller\" + 0.003*\"implement\" + 0.002*\"dale\" + 0.002*\"gopalan\" + 0.002*\"nadathur\" + 0.002*\"attached\"'),\n",
       " (49,\n",
       "  '0.007*\"frame\" + 0.007*\"slot\" + 0.004*\"taxonomy\" + 0.003*\"dependency\" + 0.002*\"rating\" + 0.002*\"slotbased\" + 0.002*\"isa\" + 0.001*\"sens\" + 0.001*\"classbased\" + 0.001*\"estimated\"'),\n",
       " (50,\n",
       "  '0.009*\"discovery\" + 0.001*\"scientific\" + 0.001*\"mill\" + 0.001*\"descriptivists\" + 0.001*\"effectset\" + 0.001*\"nickles\" + 0.001*\"paid\" + 0.001*\"inductivism\" + 0.001*\"causeset\" + 0.001*\"famous\"'),\n",
       " (51,\n",
       "  '0.009*\"icon\" + 0.008*\"possessive\" + 0.002*\"recipient\" + 0.002*\"attribute\" + 0.002*\"suggestion\" + 0.002*\"predicative\" + 0.001*\"network\" + 0.001*\"confident\" + 0.001*\"adequacy\" + 0.001*\"confidence\"'),\n",
       " (52,\n",
       "  '0.000*\"unprompted\" + 0.000*\"webber\" + 0.000*\"subgoals\" + 0.000*\"subordination\" + 0.000*\"tannen\" + 0.000*\"tod\" + 0.000*\"transferred\" + 0.000*\"uh\" + 0.000*\"started\" + 0.000*\"contextdependence\"'),\n",
       " (53,\n",
       "  '0.006*\"control\" + 0.004*\"participant\" + 0.003*\"auxtree\" + 0.003*\"offline\" + 0.003*\"righthand\" + 0.002*\"optimization\" + 0.002*\"earley\" + 0.002*\"ad\" + 0.002*\"vijayshanker\" + 0.002*\"tod\"'),\n",
       " (54,\n",
       "  '0.014*\"feature\" + 0.012*\"model\" + 0.011*\"discourse\" + 0.011*\"sentence\" + 0.009*\"structure\" + 0.008*\"language\" + 0.007*\"lexical\" + 0.007*\"algorithm\" + 0.007*\"clause\" + 0.007*\"term\"'),\n",
       " (55,\n",
       "  '0.008*\"morpheme\" + 0.007*\"surface\" + 0.007*\"morphology\" + 0.007*\"allomorph\" + 0.007*\"stem\" + 0.006*\"vowel\" + 0.006*\"twolevel\" + 0.004*\"tape\" + 0.003*\"inflected\" + 0.003*\"spanish\"'),\n",
       " (56,\n",
       "  '0.005*\"suffix\" + 0.004*\"xerox\" + 0.002*\"spanish\" + 0.001*\"itu\" + 0.001*\"file\" + 0.001*\"specially\" + 0.001*\"crater\" + 0.001*\"accomodated\" + 0.001*\"href9505035htmlcutting92cutting\" + 0.001*\"probabilistically\"'),\n",
       " (57,\n",
       "  '0.000*\"unprompted\" + 0.000*\"webber\" + 0.000*\"subgoals\" + 0.000*\"subordination\" + 0.000*\"tannen\" + 0.000*\"tod\" + 0.000*\"transferred\" + 0.000*\"uh\" + 0.000*\"started\" + 0.000*\"contextdependence\"'),\n",
       " (58,\n",
       "  '0.009*\"message\" + 0.007*\"generic\" + 0.005*\"jack\" + 0.003*\"bucket\" + 0.003*\"attribute\" + 0.003*\"sortal\" + 0.003*\"water\" + 0.002*\"plandoc\" + 0.002*\"thirty\" + 0.002*\"poured\"'),\n",
       " (59,\n",
       "  '0.006*\"hobbs\" + 0.006*\"operator\" + 0.006*\"presentation\" + 0.006*\"bfp\" + 0.003*\"fws\" + 0.003*\"proof\" + 0.003*\"subproofs\" + 0.003*\"presenting\" + 0.002*\"translatable\" + 0.002*\"allocated\"'),\n",
       " (60,\n",
       "  '0.007*\"subordinate\" + 0.001*\"experiencer\" + 0.001*\"semanticpragmatic\" + 0.001*\"garu\" + 0.001*\"observer\" + 0.001*\"subjective\" + 0.001*\"hanako\" + 0.001*\"appearing\" + 0.001*\"mc\" + 0.001*\"feeling\"'),\n",
       " (61,\n",
       "  '0.008*\"tncb\" + 0.003*\"tncbs\" + 0.003*\"ratio\" + 0.003*\"assoc\" + 0.002*\"shakeandbake\" + 0.002*\"thresholding\" + 0.001*\"illformed\" + 0.001*\"manual\" + 0.001*\"adjunction\" + 0.001*\"orthography\"'),\n",
       " (62,\n",
       "  '0.009*\"collocation\" + 0.003*\"vn\" + 0.001*\"mi\" + 0.001*\"extraction\" + 0.001*\"infinitive\" + 0.001*\"bi2\" + 0.001*\"inf\" + 0.001*\"bi5\" + 0.001*\"svcs\" + 0.001*\"half\"'),\n",
       " (63,\n",
       "  '0.010*\"evaluation\" + 0.009*\"lexicon\" + 0.009*\"pattern\" + 0.007*\"strategy\" + 0.006*\"size\" + 0.006*\"experiment\" + 0.006*\"heuristic\" + 0.006*\"parameter\" + 0.006*\"par\" + 0.005*\"relationship\"'),\n",
       " (64,\n",
       "  '0.010*\"network\" + 0.004*\"membrane\" + 0.004*\"informationtheoretical\" + 0.003*\"lambdacalculus\" + 0.003*\"layer\" + 0.003*\"distributively\" + 0.002*\"dualcoding\" + 0.002*\"associative\" + 0.002*\"activation\" + 0.002*\"lambdavariable\"'),\n",
       " (65,\n",
       "  '0.005*\"auxiliary\" + 0.005*\"genitive\" + 0.003*\"idiosyncratic\" + 0.002*\"lfg\" + 0.002*\"german\" + 0.002*\"uncertainty\" + 0.002*\"fstructure\" + 0.001*\"pollard\" + 0.001*\"projectionbased\" + 0.001*\"raising\"'),\n",
       " (66,\n",
       "  '0.000*\"unprompted\" + 0.000*\"webber\" + 0.000*\"subgoals\" + 0.000*\"subordination\" + 0.000*\"tannen\" + 0.000*\"tod\" + 0.000*\"transferred\" + 0.000*\"uh\" + 0.000*\"started\" + 0.000*\"contextdependence\"'),\n",
       " (67,\n",
       "  '0.003*\"gender\" + 0.002*\"feminine\" + 0.002*\"masculine\" + 0.002*\"plural\" + 0.002*\"thirdperson\" + 0.002*\"nounsg\" + 0.002*\"transducer\" + 0.001*\"secondperson\" + 0.001*\"verbsgp3\" + 0.001*\"collapse\"'),\n",
       " (68,\n",
       "  '0.003*\"clitics\" + 0.003*\"spanish\" + 0.002*\"questionformation\" + 0.002*\"inversion\" + 0.002*\"clitic\" + 0.002*\"inverted\" + 0.002*\"que\" + 0.002*\"hyphen\" + 0.002*\"estce\" + 0.002*\"spelling\"'),\n",
       " (69,\n",
       "  '0.004*\"genre\" + 0.004*\"discriminant\" + 0.003*\"parameter\" + 0.003*\"usenet\" + 0.002*\"news\" + 0.002*\"categorize\" + 0.001*\"display\" + 0.001*\"precategorized\" + 0.001*\"discriminating\" + 0.001*\"miscellaneous\"'),\n",
       " (70,\n",
       "  '0.003*\"phoneme\" + 0.002*\"phone\" + 0.002*\"compression\" + 0.002*\"unsupervised\" + 0.001*\"raw\" + 0.001*\"induction\" + 0.001*\"united\" + 0.001*\"phonetospeech\" + 0.001*\"phonemetophone\" + 0.001*\"deleting\"'),\n",
       " (71,\n",
       "  '0.013*\"ellipsis\" + 0.009*\"scope\" + 0.008*\"transfer\" + 0.008*\"fstructure\" + 0.006*\"quantifier\" + 0.006*\"reading\" + 0.006*\"target\" + 0.005*\"contribution\" + 0.004*\"sloppy\" + 0.003*\"strict\"'),\n",
       " (72,\n",
       "  '0.007*\"entropy\" + 0.004*\"treecutting\" + 0.002*\"rh\" + 0.002*\"cutnodes\" + 0.002*\"criterion\" + 0.002*\"handcoded\" + 0.002*\"cut\" + 0.001*\"lh\" + 0.001*\"andor\" + 0.001*\"cutnode\"'),\n",
       " (73,\n",
       "  '0.015*\"belief\" + 0.011*\"agent\" + 0.007*\"mutual\" + 0.006*\"merging\" + 0.005*\"evidence\" + 0.004*\"awm\" + 0.004*\"perplexity\" + 0.004*\"dialogue\" + 0.003*\"designworld\" + 0.003*\"irus\"'),\n",
       " (74,\n",
       "  '0.010*\"rhetorical\" + 0.001*\"extraction\" + 0.001*\"fragmentary\" + 0.001*\"connective\" + 0.001*\"detects\" + 0.001*\"exemplified\" + 0.001*\"lowest\" + 0.000*\"multidomain\" + 0.000*\"onceandforall\" + 0.000*\"medic\"'),\n",
       " (75,\n",
       "  '0.006*\"temporal\" + 0.004*\"accent\" + 0.004*\"pitch\" + 0.004*\"passage\" + 0.003*\"past\" + 0.003*\"thoracostomy\" + 0.003*\"thoracotomy\" + 0.002*\"response\" + 0.002*\"intonation\" + 0.002*\"progression\"'),\n",
       " (76,\n",
       "  '0.000*\"incremental\" + 0.000*\"quantifier\" + 0.000*\"dynamic\" + 0.000*\"fragment\" + 0.000*\"threading\" + 0.000*\"semantics\" + 0.000*\"interpretation\" + 0.000*\"semantic\" + 0.000*\"mary\" + 0.000*\"incrementally\"'),\n",
       " (77,\n",
       "  '0.006*\"motion\" + 0.005*\"spatial\" + 0.003*\"preposition\" + 0.002*\"col\" + 0.002*\"spatiotemporal\" + 0.002*\"location\" + 0.001*\"lref\" + 0.001*\"typology\" + 0.001*\"intransitive\" + 0.001*\"intrinsic\"'),\n",
       " (78,\n",
       "  '0.010*\"guessing\" + 0.008*\"referring\" + 0.008*\"unknown\" + 0.008*\"referent\" + 0.006*\"guesser\" + 0.005*\"expression\" + 0.005*\"rulesets\" + 0.005*\"dependency\" + 0.004*\"hearer\" + 0.004*\"japanesetoenglish\"'),\n",
       " (79,\n",
       "  '0.008*\"synchronous\" + 0.003*\"target\" + 0.002*\"quantitative\" + 0.002*\"treeadjoining\" + 0.002*\"ct\" + 0.002*\"qualitative\" + 0.001*\"edge\" + 0.001*\"transduction\" + 0.001*\"rewriting\" + 0.001*\"overall\"'),\n",
       " (80,\n",
       "  '0.007*\"tfs\" + 0.005*\"anaphor\" + 0.004*\"ee\" + 0.003*\"focusing\" + 0.003*\"intrasentential\" + 0.003*\"tfss\" + 0.003*\"embedded\" + 0.003*\"cell\" + 0.003*\"instruction\" + 0.002*\"nonprr\"'),\n",
       " (81,\n",
       "  '0.009*\"action\" + 0.007*\"collaborative\" + 0.005*\"user\" + 0.004*\"belief\" + 0.004*\"problemsolving\" + 0.003*\"dialogue\" + 0.003*\"proposal\" + 0.003*\"planning\" + 0.003*\"negotiation\" + 0.003*\"planbased\"'),\n",
       " (82,\n",
       "  '0.026*\"grammar\" + 0.015*\"semantic\" + 0.013*\"node\" + 0.012*\"text\" + 0.011*\"parse\" + 0.010*\"tree\" + 0.009*\"construction\" + 0.008*\"analysis\" + 0.007*\"parser\" + 0.007*\"ambiguity\"'),\n",
       " (83,\n",
       "  '0.008*\"temporal\" + 0.006*\"decisiontree\" + 0.005*\"quantifier\" + 0.004*\"bill\" + 0.004*\"seek\" + 0.004*\"scoping\" + 0.003*\"spatter\" + 0.003*\"quantified\" + 0.003*\"rhetorical\" + 0.003*\"intensional\"'),\n",
       " (84,\n",
       "  '0.007*\"dialect\" + 0.006*\"mdl\" + 0.006*\"site\" + 0.005*\"pruning\" + 0.005*\"thesaurus\" + 0.004*\"specialization\" + 0.002*\"phrasal\" + 0.002*\"distance\" + 0.002*\"nonphrasal\" + 0.002*\"tends\"'),\n",
       " (85,\n",
       "  '0.014*\"noun\" + 0.013*\"meaning\" + 0.011*\"phrase\" + 0.010*\"theory\" + 0.010*\"constraint\" + 0.010*\"interpretation\" + 0.010*\"function\" + 0.009*\"utterance\" + 0.009*\"complexity\" + 0.009*\"pronoun\"'),\n",
       " (86,\n",
       "  '0.016*\"plan\" + 0.013*\"agent\" + 0.005*\"act\" + 0.004*\"precondition\" + 0.003*\"modify\" + 0.003*\"sharedplan\" + 0.002*\"adopt\" + 0.002*\"morphology\" + 0.002*\"suffix\" + 0.002*\"combinatory\"'),\n",
       " (87,\n",
       "  '0.005*\"languagetheoretic\" + 0.004*\"annotation\" + 0.003*\"gpsg\" + 0.003*\"atwell\" + 0.003*\"eric\" + 0.002*\"generative\" + 0.002*\"characterization\" + 0.002*\"geoffrey\" + 0.002*\"souter\" + 0.002*\"modeltheoretic\"'),\n",
       " (88,\n",
       "  '0.005*\"gapping\" + 0.004*\"vpellipsis\" + 0.003*\"coherent\" + 0.002*\"topic\" + 0.002*\"nonparallel\" + 0.002*\"mismatch\" + 0.002*\"clinton\" + 0.001*\"copying\" + 0.001*\"anaphoric\" + 0.001*\"voice\"'),\n",
       " (89,\n",
       "  '0.006*\"lexicalized\" + 0.005*\"handtagged\" + 0.004*\"automaton\" + 0.004*\"reestimation\" + 0.004*\"nonlinear\" + 0.004*\"question\" + 0.003*\"maximum\" + 0.003*\"twolevel\" + 0.003*\"frequent\" + 0.003*\"compact\"'),\n",
       " (90,\n",
       "  '0.006*\"colour\" + 0.004*\"coloured\" + 0.001*\"por\" + 0.001*\"constant\" + 0.001*\"unifier\" + 0.001*\"labeling\" + 0.001*\"flexrigid\" + 0.001*\"dsps\" + 0.001*\"1c\" + 0.001*\"wellcoloured\"'),\n",
       " (91,\n",
       "  '0.008*\"lfg\" + 0.008*\"datr\" + 0.004*\"teleman\" + 0.004*\"fstructure\" + 0.002*\"transformation\" + 0.002*\"reductionistic\" + 0.002*\"descriptor\" + 0.002*\"ontology\" + 0.002*\"inheritance\" + 0.002*\"talking\"'),\n",
       " (92,\n",
       "  '0.005*\"attachment\" + 0.004*\"treelowering\" + 0.003*\"site\" + 0.002*\"lowering\" + 0.002*\"np2\" + 0.002*\"lowered\" + 0.001*\"garden\" + 0.001*\"precedence\" + 0.001*\"attached\" + 0.001*\"hurt\"'),\n",
       " (93,\n",
       "  '0.006*\"coreference\" + 0.006*\"optimisation\" + 0.005*\"clustered\" + 0.004*\"acquisition\" + 0.004*\"muc5\" + 0.003*\"coreferent\" + 0.003*\"criterion\" + 0.003*\"classification\" + 0.003*\"ti\" + 0.002*\"g1\"'),\n",
       " (94,\n",
       "  '0.000*\"unprompted\" + 0.000*\"webber\" + 0.000*\"subgoals\" + 0.000*\"subordination\" + 0.000*\"tannen\" + 0.000*\"tod\" + 0.000*\"transferred\" + 0.000*\"uh\" + 0.000*\"started\" + 0.000*\"contextdependence\"'),\n",
       " (95,\n",
       "  '0.014*\"sr\" + 0.007*\"error\" + 0.004*\"cooperative\" + 0.003*\"taxonomy\" + 0.003*\"shallow\" + 0.003*\"spelling\" + 0.002*\"sens\" + 0.002*\"pet\" + 0.001*\"damerau\" + 0.001*\"detection\"'),\n",
       " (96,\n",
       "  '0.000*\"unprompted\" + 0.000*\"webber\" + 0.000*\"subgoals\" + 0.000*\"subordination\" + 0.000*\"tannen\" + 0.000*\"tod\" + 0.000*\"transferred\" + 0.000*\"uh\" + 0.000*\"started\" + 0.000*\"contextdependence\"'),\n",
       " (97,\n",
       "  '0.000*\"unprompted\" + 0.000*\"webber\" + 0.000*\"subgoals\" + 0.000*\"subordination\" + 0.000*\"tannen\" + 0.000*\"tod\" + 0.000*\"transferred\" + 0.000*\"uh\" + 0.000*\"started\" + 0.000*\"contextdependence\"'),\n",
       " (98,\n",
       "  '0.005*\"phoneme\" + 0.002*\"lattice\" + 0.001*\"diphone\" + 0.001*\"connectionistsymbolic\" + 0.001*\"connectionist\" + 0.001*\"eojeol\" + 0.001*\"diphones\" + 0.001*\"enrolled\" + 0.001*\"skope\" + 0.001*\"phonemelevel\"'),\n",
       " (99,\n",
       "  '0.008*\"vector\" + 0.005*\"attributevalue\" + 0.005*\"ravg\" + 0.002*\"attribute\" + 0.002*\"nonterminal\" + 0.002*\"hpavg\" + 0.002*\"poly\" + 0.002*\"neighbor\" + 0.001*\"ravgs\" + 0.001*\"avg\"')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldaTfIdf.print_topics(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Making Concept Maps ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "conceptMapBow = dict()\n",
    "for tup in ldaBow.print_topics(-1):\n",
    "    s = tup[1]\n",
    "    s = s.split('+')\n",
    "    l = []\n",
    "    for ele in s:\n",
    "        l.append(ele[:-1])\n",
    "    l1 = []\n",
    "    for ele in l:\n",
    "        t = ele.split('\"')\n",
    "        l1.append(t[1])\n",
    "    conceptMapBow[tup[0]] = l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "conceptMapTfIdf = dict()\n",
    "for tup in ldaTfIdf.print_topics(-1):\n",
    "    s = tup[1]\n",
    "    s = s.split('+')\n",
    "    l = []\n",
    "    for ele in s:\n",
    "        l.append(ele[:-1])\n",
    "    l1 = []\n",
    "    for ele in l:\n",
    "        t = ele.split('\"')\n",
    "        l1.append(t[1])\n",
    "    conceptMapTfIdf[tup[0]] = l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['unprompted', 'webber', 'subgoals', 'subordination', 'tannen', 'tod', 'transferred', 'uh', 'started', 'contextdependence'], 1: ['structural', 'operation', 'current', 'disambiguation', 'lhip', 'pause', 'island', 'seems', 'constraintbased', 'focusing'], 2: ['unprompted', 'webber', 'subgoals', 'subordination', 'tannen', 'tod', 'transferred', 'uh', 'started', 'contextdependence'], 3: ['auxiliary', 'foot', 'domination', 'sfs', 'hpsg', 'lexicalized', 'link', 'schema', 'raised', 'anchored'], 4: ['tone', 'pragmatic', 'inheritance', 'defeasible', 'transcription', 'dimension', 'inference', 'typed', 'presupposition', 'multidimensional'], 5: ['bin', 'optimal', 'uniform', 'learner', 'modebased', 'falling', 'arrive', 'logarithmic', 'itai', 'severe'], 6: ['attachment', 'backedoff', 'underspecified', 'htype', 'sparse', 'prepositional', 'ibm', '3097', 'board', 'director'], 7: ['obligation', 'actor', 'conversation', 'request', 'game', 'do', 'govern', 'suggestion', 'executable', 'repairing'], 8: ['unprompted', 'webber', 'subgoals', 'subordination', 'tannen', 'tod', 'transferred', 'uh', 'started', 'contextdependence'], 9: ['nonunit', 'earley', 'goal', 'deduction', 'bias', 'indexing', 'scanning', 'disambiguation', 'base', 'pretagged'], 10: ['unprompted', 'webber', 'subgoals', 'subordination', 'tannen', 'tod', 'transferred', 'uh', 'started', 'contextdependence'], 11: ['unprompted', 'webber', 'subgoals', 'subordination', 'tannen', 'tod', 'transferred', 'uh', 'started', 'contextdependence'], 12: ['verbobject', 'fml', 'unrestricted', 'y', 'hermann', 'reinhard', '1and', 'maximization', 'redistributed', 'selforganized'], 13: ['calculus', 'parallel', 'theorem', 'suffix', 'alteration', 'parallelism', 'ruleset', 'lke', 'datalog', 'cascading'], 14: ['unknown', 'snipe', 'eats', 'meat', 'disjunct', 'disjuncts', 'link', 'o', 'connector', 'metarule'], 15: ['chain', 'nonterminal', 'gb', 'definable', 'secondorder', 'monadic', 'licensed', 'equivalence', 'trace', 'partition'], 16: ['unprompted', 'webber', 'subgoals', 'subordination', 'tannen', 'tod', 'transferred', 'uh', 'started', 'contextdependence'], 17: ['tag', 'probability', 'tagging', 'tagset', 'categorial', 'tagger', 'morphological', 'coordination', 'approach', 'state'], 18: ['fsa', 'ks', 'ltag', 'datr', 'inheritance', 'intersection', 'dcg', 'discrimination', 'inherit', 'inherits'], 19: ['theta', 'principlebased', 'xbar', 'commonsense', 'grid', 'subsystem', 'parallelism', 'indefeasible', 'lf', 'preferential'], 20: ['vector', 'distance', '20m', 'disambiguation', 'wsd', 'advantageous', 'collins', 'wsj', 'serious', 'interword'], 21: ['kanzi', 'collocation', 'compound', 'character', 'thesaurus', 'collocational', 'analyze', 'five', 'calculate', 'segmented'], 22: ['presupposition', 'tableau', 'branch', 'presuppositional', 'behaviour', 'compositionality', 'proposition', 'expansion', 'presuppose', 'negated'], 23: ['verb', 'parsing', 'input', 'type', 'source', 'representation', 'default', 'information', 'vehicle', 'description'], 24: ['chunk', 'tgl', 'compound', 'adjacency', 'chunking', 'leftbranching', 'template', 'gil', 'window', 'basenp'], 25: ['magic', 'centroid', 'cle', 'upstream', 'error', 'membership', 'translator', 'rayner', 'entropy', 'rate'], 26: ['insideoutside', 'ngram', 'induction', 'classbased', 'viterbi', 'syntacticrelationship', 'abstraction', 'mediumsized', 'postpass', 'vastly'], 27: ['lcp', 'existence', 'presupposition', 'commitment', 'stratified', 'existential', 'optimistic', 'nonexistence', 'valley', 'cohesiveness'], 28: ['unprompted', 'webber', 'subgoals', 'subordination', 'tannen', 'tod', 'transferred', 'uh', 'started', 'contextdependence'], 29: ['losing', 'maximize', 'restored', 'pgylxk', 'reducing', 'logarithm', 'obtain', 'jjrjjt', '424', '157000'], 30: ['unprompted', 'webber', 'subgoals', 'subordination', 'tannen', 'tod', 'transferred', 'uh', 'started', 'contextdependence'], 31: ['bigram', 'spelling', 'net', 'neural', 'similaritybased', 'affix', 'backoff', 'conditional', 'obligatory', 'classbased'], 32: ['assessment', 'focus', 'robust', 'hou', 'extragrammatical', 'parser', 'technology', 'higherorder', 'comparative', 'fsv'], 33: ['pitch', 'wo', 'accent', 'par', 'pronominal', 'ordering', 'accented', 'incomplete', 'efog', 'salience'], 34: ['bel', 'adjunct', 'year', 'ibm', 'toplevel', 'dash', 'subcategorisation', 'robust', 'onsabbaticalsmithnext', 'accepted'], 35: ['calculus', 'iff', 'lambek', 'dousha', 'satisfiable', 'physical', 'manually', 'resolution', 'annotation', 'permutation'], 36: ['control', 'shift', 'topic', 'dialogue', 'prompt', 'speaker', 'interruption', 'listener', 'client', 'summary'], 37: ['unknown', 'tagsets', 'swedish', 'substitution', 'substitutional', 'criterion', 'conclusion', 'substitute', 'metavariables', 'external'], 38: ['unprompted', 'webber', 'subgoals', 'subordination', 'tannen', 'tod', 'transferred', 'uh', 'started', 'contextdependence'], 39: ['fstructures', 'concurrent', 'coordinated', 'polymorphic', 'constructor', 'subsumption', 'weak', 'intensional', 'semiunification', 'symposium'], 40: ['nlg', 'planning', 'text', 'textplanning', 'determination', 'template', 'blood', 'fluent', 'content', 'naturallanguage'], 41: ['collocate', 'collocation', 'collocational', 'heavy', 'smoker', 'collocates', 'lf', 'paraphrasing', 'lexeme', 'melcuk'], 42: ['bod', 'dop', 'stsg', 'pcfg', 'isomorphic', 'exponentially', 'stochastic', 'schabes', 'carlo', 'subderivation'], 43: ['dtree', 'x2morf', 'phrasal', 'dtg', 'anaphoric', 'morphology', 'twolevel', 'integration', 'dtrees', 'wordlevel'], 44: ['unprompted', 'webber', 'subgoals', 'subordination', 'tannen', 'tod', 'transferred', 'uh', 'started', 'contextdependence'], 45: ['scaling', 'collocation', 'skeletal', 'relativised', 'leastsquares', 'square', 'calculation', 'five', 'collocational', 'unscaled'], 46: ['datr', 'descriptor', 'datrs', 'definitional', 'valuespaths', 'nodepath', 'atom', 'evaluable', 'globally', 'transparent'], 47: ['word', 'rule', 'training', 'corpus', 'cluster', 'data', 'class', 'clustering', 'translation', 'logic'], 48: ['lemma', 'programming', 'ccg', 'higherorder', 'miller', 'implement', 'dale', 'gopalan', 'nadathur', 'attached'], 49: ['frame', 'slot', 'taxonomy', 'dependency', 'rating', 'slotbased', 'isa', 'sens', 'classbased', 'estimated'], 50: ['discovery', 'scientific', 'mill', 'descriptivists', 'effectset', 'nickles', 'paid', 'inductivism', 'causeset', 'famous'], 51: ['icon', 'possessive', 'recipient', 'attribute', 'suggestion', 'predicative', 'network', 'confident', 'adequacy', 'confidence'], 52: ['unprompted', 'webber', 'subgoals', 'subordination', 'tannen', 'tod', 'transferred', 'uh', 'started', 'contextdependence'], 53: ['control', 'participant', 'auxtree', 'offline', 'righthand', 'optimization', 'earley', 'ad', 'vijayshanker', 'tod'], 54: ['feature', 'model', 'discourse', 'sentence', 'structure', 'language', 'lexical', 'algorithm', 'clause', 'term'], 55: ['morpheme', 'surface', 'morphology', 'allomorph', 'stem', 'vowel', 'twolevel', 'tape', 'inflected', 'spanish'], 56: ['suffix', 'xerox', 'spanish', 'itu', 'file', 'specially', 'crater', 'accomodated', 'href9505035htmlcutting92cutting', 'probabilistically'], 57: ['unprompted', 'webber', 'subgoals', 'subordination', 'tannen', 'tod', 'transferred', 'uh', 'started', 'contextdependence'], 58: ['message', 'generic', 'jack', 'bucket', 'attribute', 'sortal', 'water', 'plandoc', 'thirty', 'poured'], 59: ['hobbs', 'operator', 'presentation', 'bfp', 'fws', 'proof', 'subproofs', 'presenting', 'translatable', 'allocated'], 60: ['subordinate', 'experiencer', 'semanticpragmatic', 'garu', 'observer', 'subjective', 'hanako', 'appearing', 'mc', 'feeling'], 61: ['tncb', 'tncbs', 'ratio', 'assoc', 'shakeandbake', 'thresholding', 'illformed', 'manual', 'adjunction', 'orthography'], 62: ['collocation', 'vn', 'mi', 'extraction', 'infinitive', 'bi2', 'inf', 'bi5', 'svcs', 'half'], 63: ['evaluation', 'lexicon', 'pattern', 'strategy', 'size', 'experiment', 'heuristic', 'parameter', 'par', 'relationship'], 64: ['network', 'membrane', 'informationtheoretical', 'lambdacalculus', 'layer', 'distributively', 'dualcoding', 'associative', 'activation', 'lambdavariable'], 65: ['auxiliary', 'genitive', 'idiosyncratic', 'lfg', 'german', 'uncertainty', 'fstructure', 'pollard', 'projectionbased', 'raising'], 66: ['unprompted', 'webber', 'subgoals', 'subordination', 'tannen', 'tod', 'transferred', 'uh', 'started', 'contextdependence'], 67: ['gender', 'feminine', 'masculine', 'plural', 'thirdperson', 'nounsg', 'transducer', 'secondperson', 'verbsgp3', 'collapse'], 68: ['clitics', 'spanish', 'questionformation', 'inversion', 'clitic', 'inverted', 'que', 'hyphen', 'estce', 'spelling'], 69: ['genre', 'discriminant', 'parameter', 'usenet', 'news', 'categorize', 'display', 'precategorized', 'discriminating', 'miscellaneous'], 70: ['phoneme', 'phone', 'compression', 'unsupervised', 'raw', 'induction', 'united', 'phonetospeech', 'phonemetophone', 'deleting'], 71: ['ellipsis', 'scope', 'transfer', 'fstructure', 'quantifier', 'reading', 'target', 'contribution', 'sloppy', 'strict'], 72: ['entropy', 'treecutting', 'rh', 'cutnodes', 'criterion', 'handcoded', 'cut', 'lh', 'andor', 'cutnode'], 73: ['belief', 'agent', 'mutual', 'merging', 'evidence', 'awm', 'perplexity', 'dialogue', 'designworld', 'irus'], 74: ['rhetorical', 'extraction', 'fragmentary', 'connective', 'detects', 'exemplified', 'lowest', 'multidomain', 'onceandforall', 'medic'], 75: ['temporal', 'accent', 'pitch', 'passage', 'past', 'thoracostomy', 'thoracotomy', 'response', 'intonation', 'progression'], 76: ['incremental', 'quantifier', 'dynamic', 'fragment', 'threading', 'semantics', 'interpretation', 'semantic', 'mary', 'incrementally'], 77: ['motion', 'spatial', 'preposition', 'col', 'spatiotemporal', 'location', 'lref', 'typology', 'intransitive', 'intrinsic'], 78: ['guessing', 'referring', 'unknown', 'referent', 'guesser', 'expression', 'rulesets', 'dependency', 'hearer', 'japanesetoenglish'], 79: ['synchronous', 'target', 'quantitative', 'treeadjoining', 'ct', 'qualitative', 'edge', 'transduction', 'rewriting', 'overall'], 80: ['tfs', 'anaphor', 'ee', 'focusing', 'intrasentential', 'tfss', 'embedded', 'cell', 'instruction', 'nonprr'], 81: ['action', 'collaborative', 'user', 'belief', 'problemsolving', 'dialogue', 'proposal', 'planning', 'negotiation', 'planbased'], 82: ['grammar', 'semantic', 'node', 'text', 'parse', 'tree', 'construction', 'analysis', 'parser', 'ambiguity'], 83: ['temporal', 'decisiontree', 'quantifier', 'bill', 'seek', 'scoping', 'spatter', 'quantified', 'rhetorical', 'intensional'], 84: ['dialect', 'mdl', 'site', 'pruning', 'thesaurus', 'specialization', 'phrasal', 'distance', 'nonphrasal', 'tends'], 85: ['noun', 'meaning', 'phrase', 'theory', 'constraint', 'interpretation', 'function', 'utterance', 'complexity', 'pronoun'], 86: ['plan', 'agent', 'act', 'precondition', 'modify', 'sharedplan', 'adopt', 'morphology', 'suffix', 'combinatory'], 87: ['languagetheoretic', 'annotation', 'gpsg', 'atwell', 'eric', 'generative', 'characterization', 'geoffrey', 'souter', 'modeltheoretic'], 88: ['gapping', 'vpellipsis', 'coherent', 'topic', 'nonparallel', 'mismatch', 'clinton', 'copying', 'anaphoric', 'voice'], 89: ['lexicalized', 'handtagged', 'automaton', 'reestimation', 'nonlinear', 'question', 'maximum', 'twolevel', 'frequent', 'compact'], 90: ['colour', 'coloured', 'por', 'constant', 'unifier', 'labeling', 'flexrigid', 'dsps', '1c', 'wellcoloured'], 91: ['lfg', 'datr', 'teleman', 'fstructure', 'transformation', 'reductionistic', 'descriptor', 'ontology', 'inheritance', 'talking'], 92: ['attachment', 'treelowering', 'site', 'lowering', 'np2', 'lowered', 'garden', 'precedence', 'attached', 'hurt'], 93: ['coreference', 'optimisation', 'clustered', 'acquisition', 'muc5', 'coreferent', 'criterion', 'classification', 'ti', 'g1'], 94: ['unprompted', 'webber', 'subgoals', 'subordination', 'tannen', 'tod', 'transferred', 'uh', 'started', 'contextdependence'], 95: ['sr', 'error', 'cooperative', 'taxonomy', 'shallow', 'spelling', 'sens', 'pet', 'damerau', 'detection'], 96: ['unprompted', 'webber', 'subgoals', 'subordination', 'tannen', 'tod', 'transferred', 'uh', 'started', 'contextdependence'], 97: ['unprompted', 'webber', 'subgoals', 'subordination', 'tannen', 'tod', 'transferred', 'uh', 'started', 'contextdependence'], 98: ['phoneme', 'lattice', 'diphone', 'connectionistsymbolic', 'connectionist', 'eojeol', 'diphones', 'enrolled', 'skope', 'phonemelevel'], 99: ['vector', 'attributevalue', 'ravg', 'attribute', 'nonterminal', 'hpavg', 'poly', 'neighbor', 'ravgs', 'avg']}\n"
     ]
    }
   ],
   "source": [
    "print(conceptMapTfIdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ['grammar', 'rule', 'magic', 'pruning', 'constituent', 'result', 'specialization', 'edge', 'figure', 'coverage'], 1: ['transition', 'grammar', 'model', 'language', 'formalism', 'word', 'category', 'dog', 'state', 'corpus'], 2: ['word', 'speech', 'class', 'corpus', 'lexicon', 'used', 'ambiguity', 'code', 'suffix', 'training'], 3: ['language', 'word', 'processing', 'segment', 'speech', 'lexical', 'recognition', 'phoneme', 'text', 'spoken'], 4: ['colour', 'equation', 'solution', 'rule', 'variable', 'occurrence', 'coloured', 'tgl', 'primary', 'set'], 5: ['lexical', 'datr', 'word', 'theory', 'function', 'path', 'category', 'value', 'information', 'node'], 6: ['clause', 'subordinate', 'role', 'main', 'sentence', 'agent', 'semantic', 'task', 'complex', 'constraint'], 7: ['text', 'class', 'system', 'one', 'different', 'technique', 'nlg', 'use', 'used', 'number'], 8: ['rule', 'spelling', 'parsing', 'lexical', 'surface', 'algorithm', 'root', 'tabular', 'form', 'pattern'], 9: ['feature', 'structure', 'twolevel', 'morphology', 'form', 'rule', 'grammar', 'morpheme', 'stem', 'morphological'], 10: ['model', 'language', 'relation', 'translation', 'word', 'set', 'target', 'source', 'graph', 'statistical'], 11: ['language', 'sentence', 'model', 'word', 'task', 'discourse', 'evaluation', 'user', 'lexical', 'set'], 12: ['temporal', 'discourse', 'structure', 'relation', 'agent', 'plan', 'tense', 'rhetorical', 'event', 'knowledge'], 13: ['operator', 'presentation', 'proof', 'presenting', 'proverb', 'present', 'topdown', 'task', 'attentional', 'bottomup'], 14: ['grammar', 'node', 'structure', 'construction', 'rule', 'type', 'language', 'tree', 'lambek', 'description'], 15: ['np', 'discourse', 'structure', 'pronoun', 'rhetorical', 'utterance', 'anaphoric', 'phrasal', 'sentence', 'entity'], 16: ['rule', 'grammar', 'algorithm', 'language', 'parsing', 'discourse', 'generation', 'word', 'structure', 'model'], 17: ['corpus', 'english', 'scheme', 'annotation', 'mapping', 'tag', 'tagging', 'annotated', 'spoken', 'tagged'], 18: ['semantic', 'contribution', 'meaning', 'linear', 'scope', 'structure', 'syntactic', 'language', 'categorial', 'logic'], 19: ['node', 'example', 'entropy', 'tree', 'semantic', 'sentence', 'language', 'parse', 'rule', 'structure'], 20: ['context', 'word', 'vector', 'right', 'left', 'tagging', 'w', 'generalized', 'corpus', 'induction'], 21: ['type', 'feature', 'structure', 'unification', 'tfs', 'term', 'machine', 'language', 'hierarchy', 'grammar'], 22: ['rule', 'preference', 'interpretation', 'example', 'discourse', 'french', 'transfer', 'pronoun', 'utterance', 'model'], 23: ['evaluation', 'task', 'assessment', 'user', 'technology', 'data', 'project', 'system', 'comparative', 'learning'], 24: ['presupposition', 'tableau', 'rule', 'structure', 'branch', 'sentence', 'built', 'term', 'information', 'example'], 25: ['phrase', 'noun', 'possessive', 'pronoun', 'number', 'english', 'japanese', 'machine', 'translation', 'countability'], 26: ['presupposition', 'cache', 'model', 'stack', 'tableau', 'sentence', 'information', 'branch', 'framework', 'main'], 27: ['fsa', 'intersection', 'grammar', 'dcg', 'parse', 'input', 'forest', 'parsing', 'cfg', 'case'], 28: ['site', 'dialect', 'distance', 'group', 'word', 'technique', 'one', 'phonetic', 'string', 'area'], 29: ['agent', 'inference', 'strategy', 'belief', 'plan', 'evidence', 'pragmatic', 'utterance', 'assumption', 'model'], 30: ['word', 'rule', 'unknown', 'lexicon', 'guessing', 'morphological', 'tagging', 'corpus', 'rulesets', 'guesser'], 31: ['word', 'term', 'lexicon', 'training', 'corpus', 'set', 'meaning', 'tag', 'model', 'semantic'], 32: ['agent', 'strategy', 'task', 'term', 'probability', 'explicitwarrant', 'warrant', 'feature', 'reading', 'tree'], 33: ['discourse', 'cue', 'pause', 'operation', 'probability', 'attentional', 'structure', 'segment', 'focus', 'focusing'], 34: ['semantic', 'icon', 'existence', 'presupposition', 'logic', 'model', 'sentence', 'natural', 'utterance', 'language'], 35: ['word', 'interpretation', 'sentence', 'clause', 'example', 'discourse', 'source', 'preference', 'datr', 'reading'], 36: ['word', 'tree', 'model', 'node', 'decision', 'description', 'attachment', 'accessible', 'new', 'treelowering'], 37: ['term', 'feature', 'dictionary', 'prolog', 'discipline', 'general', 'word', 'used', 'sl', 'sorted'], 38: ['tree', 'decision', 'model', 'sentence', 'decisiontree', 'parse', 'question', 'node', 'spatter', 'word'], 39: ['meaning', 'semantics', 'function', 'verb', 'compositional', 'set', 'language', 'motion', 'preposition', 'natural'], 40: ['verb', 'preposition', 'data', 'function', 'motion', 'training', 'semantics', 'test', 'attachment', 'method'], 41: ['parser', 'pitch', 'robust', 'accent', 'error', 'sentence', 'pronominal', 'attentional', 'accented', 'algorithm'], 42: ['sign', 'bag', 'lexical', 'outer', 'dog', 'domain', 'generation', 'brown', 'generator', 'barked'], 43: ['relation', 'temporal', 'past', 'time', 'passage', 'planning', 'simple', 'ordering', 'account', 'explanation'], 44: ['model', 'word', 'tree', 'data', 'tag', 'pragmatic', 'method', 'node', 'using', 'training'], 45: ['grammar', 'sentence', 'complexity', 'text', 'set', 'number', 'semantic', 'analysis', 'parser', 'parsing'], 46: ['control', 'shift', 'topic', 'discourse', 'dialogue', 'participant', 'speaker', 'cue', 'utterance', 'expert'], 47: ['type', 'rule', 'grammar', 'corpus', 'word', 'function', 'semantics', 'lexical', 'language', 'tag'], 48: ['tree', 'tag', 'node', 'lexical', 'hpsg', 'auxiliary', 'feature', 'structure', 'grammar', 'verb'], 49: ['nonmonotonic', 'term', 'rule', 'default', 'sort', 'acquisition', 'variant', 'coordination', 'candidate', 'one'], 50: ['discourse', 'pronoun', 'centering', 'constraint', 'utterance', 'realized', 'proposed', 'interpretation', 'entity', 'algorithm'], 51: ['focus', 'auxiliary', 'semantic', 'approach', 'structure', 'representation', 'operator', 'analysis', 'genitive', 'multiple'], 52: ['word', 'rule', 'noun', 'set', 'language', 'constraint', 'verb', 'two', 'corpus', 'one'], 53: ['function', 'score', 'sentence', 'analysis', 'qlf', 'preference', 'factor', 'language', 'hypothesis', 'linguistic'], 54: ['category', 'left', 'pitch', 'accent', 'example', 'response', 'intonation', 'thoracostomy', 'rule', 'thoracotomy'], 55: ['model', 'sentence', 'language', 'structure', 'relation', 'belief', 'rhetorical', 'focus', 'word', 'discourse'], 56: ['clause', 'tncb', 'generation', 'goal', 'item', 'sign', 'algorithm', 'chart', 'node', 'target'], 57: ['rule', 'attributevalue', 'event', 'set', 'grammar', 'jack', 'ravg', 'second', 'language', 'syntactic'], 58: ['rule', 'semantic', 'use', 'theory', 'language', 'syntax', 'logic', 'composition', 'coordination', 'ccg'], 59: ['tag', 'corpus', 'tagging', 'word', 'training', 'probability', 'tagset', 'accuracy', 'tree', 'tagger'], 60: ['model', 'sentence', 'state', 'discourse', 'merging', 'word', 'par', 'probability', 'information', 'parse'], 61: ['algorithm', 'discourse', 'hobbs', 'bfp', 'entity', 'structure', 'example', 'focusing', 'get', 'pronoun'], 62: ['cluster', 'clustering', 'model', 'language', 'word', 'clustered', 'sentence', 'training', 'corpus', 'algorithm'], 63: ['translation', 'machine', 'japanese', 'expression', 'method', 'meaning', 'word', 'language', 'japanesetoenglish', 'based'], 64: ['rule', 'grammar', 'sentence', 'chunk', 'generic', 'order', 'word', 'input', 'structure', 'parsing'], 65: ['discovery', 'tree', 'structure', 'feature', 'grammar', 'linguistic', 'set', 'process', 'effect', 'method'], 66: ['interpretation', 'sentence', 'reading', 'clause', 'ambiguity', 'source', 'ellipsis', 'example', 'analysis', 'expression'], 67: ['text', 'vehicle', 'action', 'agent', 'plan', 'obligation', 'car', 'two', 'goal', 'type'], 68: ['rule', 'semantic', 'language', 'plan', 'agent', 'relation', 'ellipsis', 'constraint', 'expression', 'clause'], 69: ['word', 'term', 'tag', 'system', 'accuracy', 'evaluation', 'corpus', 'unknown', 'rule', 'task'], 70: ['punctuation', 'grammar', 'mark', 'sentence', 'punctuated', 'unpunctuated', 'lexical', 'expression', 'use', 'par'], 71: ['message', 'grammar', 'dependency', 'categorial', 'calculus', 'structure', 'formula', 'rule', 'proof', 'information'], 72: ['word', 'rule', 'language', 'temporal', 'grammar', 'sentence', 'speech', 'structure', 'example', 'model'], 73: ['case', 'slot', 'frame', 'data', 'model', 'dependency', 'method', 'pattern', 'based', 'learning'], 74: ['grammar', 'parser', 'parsing', 'rule', 'structure', 'parse', 'coordination', 'sentence', 'parallel', 'argument'], 75: ['language', 'sentence', 'evaluation', 'case', 'translation', 'source', 'pronoun', 'phrase', 'example', 'interpretation'], 76: ['grammar', 'tree', 'feature', 'structure', 'rule', 'set', 'parsing', 'unificationbased', 'constraint', 'parser'], 77: ['collocation', 'verb', 'combination', 'extracted', 'vn', 'precision', 'word', 'corpus', 'noun', 'extraction'], 78: ['input', 'parse', 'sentence', 'word', 'par', 'heuristic', 'parser', 'feature', 'evaluation', 'skipping'], 79: ['word', 'vector', 'cooccurrence', 'distance', 'using', 'disambiguation', 'similarity', 'english', 'sense', 'dictionary'], 80: ['constraint', 'ellipsis', 'antecedent', 'term', 'type', 'substitution', 'variable', 'set', 'index', 'language'], 81: ['theory', 'feature', 'grammar', 'unification', 'problem', 'complexity', 'section', 'string', 'neural', 'net'], 82: ['meaning', 'fstructure', 'semantic', 'verb', 'logic', 'intensional', 'seek', 'lexical', 'fstructures', 'constructor'], 83: ['belief', 'proposed', 'model', 'user', 'action', 'agent', 'evidence', 'system', 'collaborative', 'german'], 84: ['tree', 'derivation', 'synchronous', 'tone', 'tag', 'pair', 'transcription', 'definition', 'sequence', 'program'], 85: ['lfg', 'coreference', 'phrase', 'feature', 'fstructure', 'rule', 'information', 'tree', 'muc5', 'coreferent'], 86: ['gapping', 'inference', 'vpellipsis', 'representation', 'form', 'example', 'discourse', 'coherent', 'construction', 'semantic'], 87: ['grammar', 'algorithm', 'data', 'model', 'tagset', 'rule', 'insideoutside', 'training', 'language', 'ngram'], 88: ['model', 'probability', 'bigram', 'estimate', 'word', 'unseen', 'similarity', 'similaritybased', 'backoff', 'language'], 89: ['expression', 'referring', 'generation', 'referent', 'hearer', 'language', 'natural', 'identification', 'intended', 'description'], 90: ['bracketings', 'dcglike', 'manuallydisambiguated', 'choice', 'likely', 'post', '7080', '400', 'posing', 'parsertreebank'], 91: ['verb', 'word', 'construction', 'noun', 'information', 'similarity', 'semantic', 'concept', 'form', 'taxonomy'], 92: ['training', 'data', 'word', 'bin', 'model', 'noun', 'statistical', 'compound', 'set', 'instance'], 93: ['cluster', 'entropy', 'model', 'data', 'node', 'set', 'distribution', 'tree', 'clustering', 'noun'], 94: ['word', 'language', 'semantic', 'representation', 'sentence', 'grammar', 'syntactic', 'interpretation', 'model', 'semantics'], 95: ['language', 'tree', 'node', 'set', 'theory', 'structure', 'complexity', 'class', 'grammar', 'chain'], 96: ['rule', 'word', 'grammar', 'language', 'model', 'set', 'input', 'relation', 'tree', 'form'], 97: ['algorithm', 'parsing', 'tabular', 'lr', 'model', 'grammar', 'discourse', 'default', 'input', 'number'], 98: ['feature', 'structure', 'entry', 'rule', 'node', 'lexical', 'type', 'lemma', 'probability', 'allomorph'], 99: ['function', 'set', 'language', 'value', 'sentence', 'datr', 'discovery', 'path', 'semantics', 'grammar']}\n"
     ]
    }
   ],
   "source": [
    "print(conceptMapBow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
